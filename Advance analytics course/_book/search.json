[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Data Analytics Course",
    "section": "",
    "text": "Preface\nWelcome to the Advanced Analytics Course! This course is designed to provide you with hands-on experience using real-world data to guide decision-making processes. You will work with an Octagonal Analytics Platform (Plátano), which integrates data analysis techniques into anticipative decision-making workflows.\nRecommended readings for Plátano, see:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Heath, Chip, and Dan Heath. 2007. Made to Stick: Why Some Ideas\nSurvive and Others Die. New York: Random House.\n\n\nHutchinson, Kylie. 2017. A Short Primer on Innovative Evaluation\nReporting. First. Kylie Hutchinson.\n\n\nPeña, D. 2002. Análisis Multivariante de Datos.\nMcGraw-Hill Interamericana de España S.L. https://books.google.com.co/books?id=TrVlAAAACAAJ.\n\n\nPerez-Coronado, Andres. 2016a. “Inteligencia Colectiva:\nAnticipación a Corto Plazo de Las Problemáticas de Convivencia.”\nRevista Criminalidad 58: 223–40. https://doi.org/https://doi.org/10.47741/17943108.120.\n\n\n———. 2016b. Policía Para El Desarrollo Humano (PDH). Primera.\nEditorial Ibanez.\n\n\nServicio de Policía, Jefatura Nacional del. 2024. Analítica de Datos\nPara La Seguridad Ciudadana. Edited by Jenny Andrea Lozano Medina.\nEditorial de la Dirección de Educación Policial de la Policía Nacional\nde Colombia. https://doi.org/10.22335/2qjz0m48.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "1. Issue for Decision-Making.html",
    "href": "1. Issue for Decision-Making.html",
    "title": "1  Issue for Decision-Making",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "2. Key Players and Topics.html",
    "href": "2. Key Players and Topics.html",
    "title": "2  Key Players and Topics",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Key Players and Topics</span>"
    ]
  },
  {
    "objectID": "Issue for Decision-Making.html",
    "href": "Issue for Decision-Making.html",
    "title": "1  Issue for Decision-Making",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "Key Players and Topics.html",
    "href": "Key Players and Topics.html",
    "title": "2  Key Players and Topics",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Key Players and Topics</span>"
    ]
  },
  {
    "objectID": "Collecting and Connecting Data.html",
    "href": "Collecting and Connecting Data.html",
    "title": "3  Collecting and Connecting Data",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Collecting and Connecting Data</span>"
    ]
  },
  {
    "objectID": "1.Issue for Decision-Making.html",
    "href": "1.Issue for Decision-Making.html",
    "title": "1  Issue for Decision-Making",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "2.Key Players and Topics.html",
    "href": "2.Key Players and Topics.html",
    "title": "2  Key Players and Topics",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Key Players and Topics</span>"
    ]
  },
  {
    "objectID": "3.Collecting and Connecting Data.html",
    "href": "3.Collecting and Connecting Data.html",
    "title": "3  Collecting and Connecting Data",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Collecting and Connecting Data</span>"
    ]
  },
  {
    "objectID": "3. Collecting and Connecting Data.html",
    "href": "3. Collecting and Connecting Data.html",
    "title": "3  Collecting and Connecting Data",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Collecting and Connecting Data</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html",
    "href": "1-Issue-for-Decision-Making.html",
    "title": "1  Issue for Decision-Making",
    "section": "",
    "text": "Exploratory Analysis of Multidimensional Data",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "2-Key-Players-and-Topics.html",
    "href": "2-Key-Players-and-Topics.html",
    "title": "2  Key Players and Topics",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Key Players and Topics</span>"
    ]
  },
  {
    "objectID": "3-Collecting-and-Connecting-Data.html",
    "href": "3-Collecting-and-Connecting-Data.html",
    "title": "3  Collecting and Connecting Data",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Collecting and Connecting Data</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#multivariate-exploratory-analysis",
    "href": "1-Issue-for-Decision-Making.html#multivariate-exploratory-analysis",
    "title": "1  Issue for Decision-Making",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#exploratory-analysis-of-multidimensional-data",
    "href": "1-Issue-for-Decision-Making.html#exploratory-analysis-of-multidimensional-data",
    "title": "1  Issue for Decision-Making",
    "section": "",
    "text": "1.1.1 Import data set, require packages and a short summary of data\n\n# working directory\n#setwd(dirname(rstudioapi::getSourceEditorContext()$path))\n\n# packages\nlist_packages = c('readxl', 'dplyr', 'moments', 'tidyr', 'tibble', 'gt', 'ggplot2', 'fmsb')\nnew.packages = list_packages[!(list_packages %in% installed.packages()[,\"Package\"])]\nif (length(new.packages)) {\n  install.packages(new.packages)\n}\nfor (package in list_packages){\n  library(package, character.only = T)\n}\n\n# Load the dataset\n# Define the file path\nfile_path &lt;- paste0(getwd(),\"/delitos_2024_v2.xlsx\")\n\n# Load the specific sheet from the Excel file\ndelitos_data &lt;- read_excel(file_path, sheet = \"2024\")\n\ndim(delitos_data)\n\n[1] 1215   19\n\nsummary(delitos_data)\n\n    UNIDAD            ESTACION            SEXUALES        EXTORSION     \n Length:1215        Length:1215        Min.   :  0.00   Min.   :  0.00  \n Class :character   Class :character   1st Qu.:  2.00   1st Qu.:  0.00  \n Mode  :character   Mode  :character   Median :  6.00   Median :  2.00  \n                                       Mean   : 24.47   Mean   : 10.15  \n                                       3rd Qu.: 16.00   3rd Qu.:  7.00  \n                                       Max.   :923.00   Max.   :337.00  \n   HOMICIDIO       HOMICIDIO_AT      SEMOVIENTES      AUTOMOTORES     \n Min.   :  0.00   Min.   :  0.000   Min.   : 0.000   Min.   :  0.000  \n 1st Qu.:  0.00   1st Qu.:  0.000   1st Qu.: 0.000   1st Qu.:  0.000  \n Median :  3.00   Median :  2.000   Median : 0.000   Median :  0.000  \n Mean   : 10.96   Mean   :  5.635   Mean   : 0.837   Mean   :  8.995  \n 3rd Qu.: 11.00   3rd Qu.:  6.000   3rd Qu.: 1.000   3rd Qu.:  3.000  \n Max.   :236.00   Max.   :105.000   Max.   :22.000   Max.   :909.000  \n     BANCOS           COMERCIO        MOTOCICLETAS        PERSONAS      \n Min.   :0.00000   Min.   :   0.00   Min.   :   0.00   Min.   :    0.0  \n 1st Qu.:0.00000   1st Qu.:   1.00   1st Qu.:   0.00   1st Qu.:    3.0  \n Median :0.00000   Median :   4.00   Median :   3.00   Median :   10.0  \n Mean   :0.04197   Mean   :  28.74   Mean   :  31.03   Mean   :  252.7  \n 3rd Qu.:0.00000   3rd Qu.:  14.00   3rd Qu.:  14.00   3rd Qu.:   50.0  \n Max.   :5.00000   Max.   :1033.00   Max.   :1138.00   Max.   :12700.0  \n   PIRATERIA       RESIDENCIAS      LESIONES_AT         LESIONES      \n Min.   :0.0000   Min.   :  0.00   Min.   :   0.00   Min.   :   0.00  \n 1st Qu.:0.0000   1st Qu.:  1.00   1st Qu.:   1.00   1st Qu.:   6.00  \n Median :0.0000   Median :  4.00   Median :   5.00   Median :  17.00  \n Mean   :0.1029   Mean   : 23.36   Mean   :  38.12   Mean   :  72.93  \n 3rd Qu.:0.0000   3rd Qu.: 16.50   3rd Qu.:  28.00   3rd Qu.:  50.00  \n Max.   :7.0000   Max.   :804.00   Max.   :1118.00   Max.   :2170.00  \n   SECUESTRO        TERRORISMO      INTRAFAMILIAR   \n Min.   :0.0000   Min.   : 0.0000   Min.   :   0.0  \n 1st Qu.:0.0000   1st Qu.: 0.0000   1st Qu.:   5.0  \n Median :0.0000   Median : 0.0000   Median :  14.0  \n Mean   :0.2296   Mean   : 0.1514   Mean   : 108.8  \n 3rd Qu.:0.0000   3rd Qu.: 0.0000   3rd Qu.:  46.5  \n Max.   :7.0000   Max.   :15.0000   Max.   :5142.0  \n\n\n\n\n1.1.2 Skewness\nSkewness measures the asymmetry of a data distribution around its mean. It is defined mathematically as:\n\\([\ng_1 = \\frac{n}{(n-1)(n-2)} \\sum \\left( \\frac{x_i - \\bar{x}}{\\sigma} \\right)^3\n]\\)\nwhere:\n\n\\(( n )\\): Number of observations,\n\\(( x_i )\\): Individual data points,\n\\(( \\bar{x} )\\): Mean of the data,\n\\(( \\sigma )\\): Standard deviation of the data.\n\nA skewness of \\(( 0 )\\) indicates a perfectly symmetric distribution. Positive skewness \\(( g_1 &gt; 0 )\\) signifies a longer tail on the right side of the distribution, while negative skewness \\(( g_1 &lt; 0 )\\) indicates a longer tail on the left. The code below calculates skewness for all numeric columns in delitos_data and presents the results in a formatted table:\n\n# skewness\ndelitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%  # Select only numeric columns\n  summarise(across(everything(), ~ skewness(.x, na.rm = TRUE))) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  rename(Skewness = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nSkewness\n\n\n\n\nSEXUALES\n7.596326\n\n\nEXTORSION\n5.971174\n\n\nHOMICIDIO\n4.229098\n\n\nHOMICIDIO_AT\n4.081334\n\n\nSEMOVIENTES\n4.632308\n\n\nAUTOMOTORES\n12.228396\n\n\nBANCOS\n9.642696\n\n\nCOMERCIO\n6.349052\n\n\nMOTOCICLETAS\n5.836587\n\n\nPERSONAS\n7.976975\n\n\nPIRATERIA\n7.097872\n\n\nRESIDENCIAS\n6.235526\n\n\nLESIONES_AT\n5.210738\n\n\nLESIONES\n5.487627\n\n\nSECUESTRO\n4.509626\n\n\nTERRORISMO\n10.751395\n\n\nINTRAFAMILIAR\n8.130638\n\n\n\n\n\n\n\n\n\n1.1.3 Kurtosis\nKurtosis measures the heaviness of the tails of a data distribution relative to a normal distribution. It is defined mathematically as:\n\\([\ng_2 = \\left[ \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum \\left( \\frac{x_i - \\bar{x}}{\\sigma} \\right)^4 \\right] - \\frac{3(n-1)^2}{(n-2)(n-3)}\n]\\)\nwhere:\n\n\\(( n )\\): Number of observations,\n\\(( x_i )\\): Individual data points,\n\\(( \\bar{x} )\\): Mean of the data,\n\\(( \\sigma )\\): Standard deviation of the data.\n\nA kurtosis of \\(( 0 )\\) (excess kurtosis) indicates tail behavior similar to a normal distribution. Positive kurtosis \\(( g_2 &gt; 0 )\\) signifies heavier tails and more outliers (leptokurtic), while negative kurtosis \\(( g_2 &lt; 0 )\\) indicates lighter tails and fewer outliers (platykurtic).\n\n# kurtosis\ndelitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%  # Select only numeric columns\n  summarise(across(everything(), ~ kurtosis(.x, na.rm = TRUE))) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  rename(Kurtosis = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nKurtosis\n\n\n\n\nSEXUALES\n75.03185\n\n\nEXTORSION\n49.16431\n\n\nHOMICIDIO\n26.71778\n\n\nHOMICIDIO_AT\n24.81953\n\n\nSEMOVIENTES\n33.30167\n\n\nAUTOMOTORES\n218.88105\n\n\nBANCOS\n129.74066\n\n\nCOMERCIO\n52.10447\n\n\nMOTOCICLETAS\n46.30865\n\n\nPERSONAS\n77.70454\n\n\nPIRATERIA\n63.52728\n\n\nRESIDENCIAS\n57.48987\n\n\nLESIONES_AT\n42.09322\n\n\nLESIONES\n44.81022\n\n\nSECUESTRO\n25.93444\n\n\nTERRORISMO\n142.88902\n\n\nINTRAFAMILIAR\n86.90023\n\n\n\n\n\n\n\n\n\n1.1.4 Coefficient of Variation\nThe coefficient of variation (CV) measures the relative variability of a dataset, expressed as a percentage. It is defined mathematically as:\n\\([\nCV = \\left( \\frac{\\sigma}{\\bar{x}} \\right) \\times 100\n]\\)\nwhere:\n\n\\(( \\sigma )\\): Standard deviation of the data,\n\\(( \\bar{x} )\\): Mean of the data.\n\nThe coefficient of variation is particularly useful for comparing the variability of datasets with different units or widely different means. A lower CV indicates less variability relative to the mean, while a higher CV indicates greater variability.\n\n# Standard Deviation (SD)\ndelitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%\n  summarise(across(everything(), ~ sd(.x, na.rm = TRUE))) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  rename(SD = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nSD\n\n\n\n\nSEXUALES\n72.4273234\n\n\nEXTORSION\n28.2974032\n\n\nHOMICIDIO\n22.2473414\n\n\nHOMICIDIO_AT\n10.9360033\n\n\nSEMOVIENTES\n1.9583247\n\n\nAUTOMOTORES\n41.0024306\n\n\nBANCOS\n0.2705466\n\n\nCOMERCIO\n90.6639920\n\n\nMOTOCICLETAS\n92.7418287\n\n\nPERSONAS\n1051.7137659\n\n\nPIRATERIA\n0.5199004\n\n\nRESIDENCIAS\n60.1003484\n\n\nLESIONES_AT\n93.0326537\n\n\nLESIONES\n172.6644196\n\n\nSECUESTRO\n0.7958569\n\n\nTERRORISMO\n0.9130822\n\n\nINTRAFAMILIAR\n369.1367190\n\n\n\n\n\n\n# variation\ndelitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%  # Select only numeric columns\n  summarise(\n    across(\n      everything(),\n      ~ ifelse(mean(.x, na.rm = TRUE) != 0, \n               sd(.x, na.rm = TRUE) / mean(.x, na.rm = TRUE), \n               NA),  # Compute CV safely\n      .names = \"{col}\"\n    )\n  ) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  rename(Variation = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nVariation\n\n\n\n\nSEXUALES\n2.959847\n\n\nEXTORSION\n2.788204\n\n\nHOMICIDIO\n2.029471\n\n\nHOMICIDIO_AT\n1.940877\n\n\nSEMOVIENTES\n2.339591\n\n\nAUTOMOTORES\n4.558327\n\n\nBANCOS\n6.445374\n\n\nCOMERCIO\n3.154817\n\n\nMOTOCICLETAS\n2.988657\n\n\nPERSONAS\n4.162550\n\n\nPIRATERIA\n5.053432\n\n\nRESIDENCIAS\n2.573097\n\n\nLESIONES_AT\n2.440774\n\n\nLESIONES\n2.367695\n\n\nSECUESTRO\n3.465829\n\n\nTERRORISMO\n6.029320\n\n\nINTRAFAMILIAR\n3.393853\n\n\n\n\n\n\n\n\n\n1.1.5 Median Absolute Deviation MAD and MAD/median\nThe Median Absolute Deviation (MAD) is a robust measure of variability that quantifies the dispersion of a dataset. It is defined as the median of the absolute deviations from the median of the data:\n\\([\n\\text{MAD} = \\text{median} \\left( \\left| x_i - \\text{median}(x) \\right| \\right)\n]\\)\nwhere:\n\n( x_i ): Individual data points,\n( (x) ): Median of the data.\n\nThe MAD/Median ratio is a normalized measure of dispersion, calculated as:\n\\([\n\\text{MAD/Median} = \\frac{\\text{MAD}}{\\text{median}(x)}\n]\\)\nThis ratio provides a scale-independent measure of variability, making it useful for comparing the dispersion of datasets with different units or scales. A higher MAD/Median ratio indicates greater relative variability.\n\n# MAD\ndelitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%\n  summarise(across(everything(), ~ mad(.x, na.rm = TRUE))) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  rename(MAD = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nMAD\n\n\n\n\nSEXUALES\n7.4130\n\n\nEXTORSION\n2.9652\n\n\nHOMICIDIO\n4.4478\n\n\nHOMICIDIO_AT\n2.9652\n\n\nSEMOVIENTES\n0.0000\n\n\nAUTOMOTORES\n0.0000\n\n\nBANCOS\n0.0000\n\n\nCOMERCIO\n5.9304\n\n\nMOTOCICLETAS\n4.4478\n\n\nPERSONAS\n13.3434\n\n\nPIRATERIA\n0.0000\n\n\nRESIDENCIAS\n5.9304\n\n\nLESIONES_AT\n7.4130\n\n\nLESIONES\n19.2738\n\n\nSECUESTRO\n0.0000\n\n\nTERRORISMO\n0.0000\n\n\nINTRAFAMILIAR\n17.7912\n\n\n\n\n\n\n# MAD/Median\ndelitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%\n  summarise(across(everything(), ~ ifelse(\n    median(.x, na.rm = TRUE) != 0,\n    mad(.x, na.rm = TRUE) / median(.x, na.rm = TRUE),\n    NA\n  ))) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  rename(`MAD/Median` = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nMAD/Median\n\n\n\n\nSEXUALES\n1.235500\n\n\nEXTORSION\n1.482600\n\n\nHOMICIDIO\n1.482600\n\n\nHOMICIDIO_AT\n1.482600\n\n\nSEMOVIENTES\nNA\n\n\nAUTOMOTORES\nNA\n\n\nBANCOS\nNA\n\n\nCOMERCIO\n1.482600\n\n\nMOTOCICLETAS\n1.482600\n\n\nPERSONAS\n1.334340\n\n\nPIRATERIA\nNA\n\n\nRESIDENCIAS\n1.482600\n\n\nLESIONES_AT\n1.482600\n\n\nLESIONES\n1.133753\n\n\nSECUESTRO\nNA\n\n\nTERRORISMO\nNA\n\n\nINTRAFAMILIAR\n1.270800\n\n\n\n\n\n\ndelitos_data %&gt;%\n  select(SEMOVIENTES, AUTOMOTORES, BANCOS, PIRATERIA) %&gt;%\n  summary()\n\n  SEMOVIENTES      AUTOMOTORES          BANCOS          PIRATERIA     \n Min.   : 0.000   Min.   :  0.000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.: 0.000   1st Qu.:  0.000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median : 0.000   Median :  0.000   Median :0.00000   Median :0.0000  \n Mean   : 0.837   Mean   :  8.995   Mean   :0.04197   Mean   :0.1029  \n 3rd Qu.: 1.000   3rd Qu.:  3.000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :22.000   Max.   :909.000   Max.   :5.00000   Max.   :7.0000",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#graphical",
    "href": "1-Issue-for-Decision-Making.html#graphical",
    "title": "1  Issue for Decision-Making",
    "section": "1.2 Graphical",
    "text": "1.2 Graphical\n\n# Load necessary library\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Transform the data to a long format for ggplot\ndelitos_long &lt;- delitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%  # Select only numeric columns\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Value\")\n\n# Create faceted histograms\nggplot(delitos_long, aes(x = Value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Distributions of Crime Data\",\n    x = \"Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 5)  # Reduce the font size of X-axis text\n  )\n\n\n\n\n\n\n\n\nIn log variables\n\n# Transform the data to long format and apply log transformation\ndelitos_long_log &lt;- delitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%\n  mutate(across(everything(), ~ log(.x), .names = \"{col}\")) %&gt;%  # Log transform (log(x + 1) to avoid log(0))\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Log Value\")\n\n# Create faceted histograms for log-transformed values\nggplot(delitos_long_log, aes(x = `Log Value`)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Log-Transformed Distributions of Crime Data\",\n    x = \"Log Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 3)  # Reduce the font size of X-axis text\n  )",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#graphical-analysis",
    "href": "1-Issue-for-Decision-Making.html#graphical-analysis",
    "title": "1  Issue for Decision-Making",
    "section": "2.1 Graphical analysis",
    "text": "2.1 Graphical analysis\n\n# Load necessary library\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Transform the data to a long format for ggplot\ndelitos_long &lt;- delitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%  # Select only numeric columns\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Value\")\n\n# Create faceted histograms\nggplot(delitos_long, aes(x = Value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Distributions of Crime Data\",\n    x = \"Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 5)  # Reduce the font size of X-axis text\n  )\n\n\n\n\n\n\n\n\nLog-transformed crime data distributions\n\n# Transform the data to long format and apply log transformation\ndelitos_long_log &lt;- delitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%\n  mutate(across(everything(), ~ log(.x), .names = \"{col}\")) %&gt;%  # Log transform (log(x + 1) to avoid log(0))\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Log Value\")\n\n# Create faceted histograms for log-transformed values\nggplot(delitos_long_log, aes(x = `Log Value`)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Log-Transformed Distributions of Crime Data\",\n    x = \"Log Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 3)  # Reduce the font size of X-axis text\n  )\n\n\n\n\n\n\n\n\n\n# Transform the data to long format and apply log transformation\ndelitos_long_log &lt;- delitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%\n  mutate(across(everything(), ~ log(.x), .names = \"{col}\")) %&gt;%  # Log transform (log(x + 1) to avoid log(0))\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Log Value\")\n\n# Create faceted histograms for log-transformed values\nggplot(delitos_long_log, aes(x = `Log Value`)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Log-Transformed Distributions of Crime Data\",\n    x = \"Log Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 3)  # Reduce the font size of X-axis text\n  )",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "index.html#course-schedule",
    "href": "index.html#course-schedule",
    "title": "Advanced Data Analytics Course",
    "section": "Course schedule",
    "text": "Course schedule",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#evaluation-activities",
    "href": "index.html#evaluation-activities",
    "title": "Advanced Data Analytics Course",
    "section": "Evaluation activities",
    "text": "Evaluation activities",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#rubric",
    "href": "index.html#rubric",
    "title": "Advanced Data Analytics Course",
    "section": "Rubric",
    "text": "Rubric\n\n\n\n\nHeath, Chip, and Dan Heath. 2007. Made to Stick: Why Some Ideas Survive and Others Die. New York: Random House.\n\n\nHutchinson, Kylie. 2017. A Short Primer on Innovative Evaluation Reporting. First. Kylie Hutchinson.\n\n\nPerez-Coronado, Andres. 2016a. “Inteligencia Colectiva: Anticipación a Corto Plazo de Las Problemáticas de Convivencia.” Revista Criminalidad 58: 223–40. https://doi.org/https://doi.org/10.47741/17943108.120.\n\n\n———. 2016b. Policía Para El Desarrollo Humano (PDH). Primera. Editorial Ibanez.\n\n\nServicio de Policía, Jefatura Nacional del. 2024. Analítica de Datos Para La Seguridad Ciudadana. Edited by Jenny Andrea Lozano Medina. Editorial de la Dirección de Educación Policial de la Policía Nacional de Colombia. https://doi.org/10.22335/2qjz0m48.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#import-data-set-require-packages-and-a-short-summary-of-data",
    "href": "1-Issue-for-Decision-Making.html#import-data-set-require-packages-and-a-short-summary-of-data",
    "title": "1  Issue for Decision-Making",
    "section": "1.1 Import data set, require packages and a short summary of data",
    "text": "1.1 Import data set, require packages and a short summary of data\n\n# working directory\n#setwd(dirname(rstudioapi::getSourceEditorContext()$path))\n\n# packages\nlist_packages = c('readxl', 'dplyr', 'moments', 'tidyr', 'tibble', 'gt', 'ggplot2', 'fmsb')\nnew.packages = list_packages[!(list_packages %in% installed.packages()[,\"Package\"])]\nif (length(new.packages)) {\n  install.packages(new.packages)\n}\nfor (package in list_packages){\n  library(package, character.only = T)\n}\n\n# Load the dataset\n# Define the file path\nfile_path &lt;- paste0(getwd(),\"/delitos_2024_v2.xlsx\")\n\n# Load the specific sheet from the Excel file\ndelitos_data &lt;- read_excel(file_path, sheet = \"2024\")\n\ndim(delitos_data)\n\n[1] 1215   19\n\nsummary(delitos_data)\n\n    UNIDAD            ESTACION            SEXUALES        EXTORSION     \n Length:1215        Length:1215        Min.   :  0.00   Min.   :  0.00  \n Class :character   Class :character   1st Qu.:  2.00   1st Qu.:  0.00  \n Mode  :character   Mode  :character   Median :  6.00   Median :  2.00  \n                                       Mean   : 24.47   Mean   : 10.15  \n                                       3rd Qu.: 16.00   3rd Qu.:  7.00  \n                                       Max.   :923.00   Max.   :337.00  \n   HOMICIDIO       HOMICIDIO_AT      SEMOVIENTES      AUTOMOTORES     \n Min.   :  0.00   Min.   :  0.000   Min.   : 0.000   Min.   :  0.000  \n 1st Qu.:  0.00   1st Qu.:  0.000   1st Qu.: 0.000   1st Qu.:  0.000  \n Median :  3.00   Median :  2.000   Median : 0.000   Median :  0.000  \n Mean   : 10.96   Mean   :  5.635   Mean   : 0.837   Mean   :  8.995  \n 3rd Qu.: 11.00   3rd Qu.:  6.000   3rd Qu.: 1.000   3rd Qu.:  3.000  \n Max.   :236.00   Max.   :105.000   Max.   :22.000   Max.   :909.000  \n     BANCOS           COMERCIO        MOTOCICLETAS        PERSONAS      \n Min.   :0.00000   Min.   :   0.00   Min.   :   0.00   Min.   :    0.0  \n 1st Qu.:0.00000   1st Qu.:   1.00   1st Qu.:   0.00   1st Qu.:    3.0  \n Median :0.00000   Median :   4.00   Median :   3.00   Median :   10.0  \n Mean   :0.04197   Mean   :  28.74   Mean   :  31.03   Mean   :  252.7  \n 3rd Qu.:0.00000   3rd Qu.:  14.00   3rd Qu.:  14.00   3rd Qu.:   50.0  \n Max.   :5.00000   Max.   :1033.00   Max.   :1138.00   Max.   :12700.0  \n   PIRATERIA       RESIDENCIAS      LESIONES_AT         LESIONES      \n Min.   :0.0000   Min.   :  0.00   Min.   :   0.00   Min.   :   0.00  \n 1st Qu.:0.0000   1st Qu.:  1.00   1st Qu.:   1.00   1st Qu.:   6.00  \n Median :0.0000   Median :  4.00   Median :   5.00   Median :  17.00  \n Mean   :0.1029   Mean   : 23.36   Mean   :  38.12   Mean   :  72.93  \n 3rd Qu.:0.0000   3rd Qu.: 16.50   3rd Qu.:  28.00   3rd Qu.:  50.00  \n Max.   :7.0000   Max.   :804.00   Max.   :1118.00   Max.   :2170.00  \n   SECUESTRO        TERRORISMO      INTRAFAMILIAR   \n Min.   :0.0000   Min.   : 0.0000   Min.   :   0.0  \n 1st Qu.:0.0000   1st Qu.: 0.0000   1st Qu.:   5.0  \n Median :0.0000   Median : 0.0000   Median :  14.0  \n Mean   :0.2296   Mean   : 0.1514   Mean   : 108.8  \n 3rd Qu.:0.0000   3rd Qu.: 0.0000   3rd Qu.:  46.5  \n Max.   :7.0000   Max.   :15.0000   Max.   :5142.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#skewness",
    "href": "1-Issue-for-Decision-Making.html#skewness",
    "title": "1  Issue for Decision-Making",
    "section": "1.2 Skewness",
    "text": "1.2 Skewness\nSkewness measures the asymmetry of a data distribution around its mean. It is defined mathematically as:\n\\(g_1 = \\frac{n}{(n-1)(n-2)} \\sum \\left( \\frac{x_i - \\bar{x}}{\\sigma} \\right)^3\\)\nwhere:\n\n\\(( n )\\): Number of observations,\n\\(( x_i )\\): Individual data points,\n\\(( \\bar{x} )\\): Mean of the data,\n\\(( \\sigma )\\): Standard deviation of the data.\n\nA skewness of \\(( 0 )\\) indicates a perfectly symmetric distribution. Positive skewness \\(( g_1 &gt; 0 )\\) signifies a longer tail on the right side of the distribution, while negative skewness \\(( g_1 &lt; 0 )\\) indicates a longer tail on the left. The code below calculates skewness for all numeric columns in delitos_data and presents the results in a formatted table:\n\n# step by step\nn &lt;- length(delitos_data$sum_24HP) \nmean_x &lt;- mean(delitos_data$sum_24HP)\nsd_x &lt;- sd(delitos_data$sum_24HP)  # Uses (n-1) denominator\nz_scores &lt;- (delitos_data$sum_24HP - mean_x) / sd_x\nz_cubed &lt;- z_scores^3\nsum_cubed &lt;- sum(z_cubed)\nskewness &lt;- (n / ((n - 1) * (n - 2))) * sum_cubed\npaste0('sum_24HP: ', skewness)\n\n[1] \"sum_24HP: 162.24014081153\"\n\n# function\nskewness(delitos_data$sum_24HP, na.rm = TRUE)\n\n[1] 162.2347\n\n# skewness\ndelitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  summarise(across(everything(), ~ skewness(.x, na.rm = TRUE))) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  mutate(V1 = round(V1, 2)) %&gt;%\n  rename(Skewness = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nSkewness\n\n\n\n\nsum_24HOM\n10.35\n\n\nsum_24LP\n149.76\n\n\nsum_24VI\n170.08\n\n\nsum_24DS\n161.47\n\n\nsum_24HP\n162.23\n\n\nsum_24HR\n67.13\n\n\nsum_24HC\n137.30\n\n\nsum_24HA\n9.58\n\n\nsum_24HM\n9.11\n\n\nsum_24SS\n143.24\n\n\nsum_24SE\n148.86\n\n\nsum_24EX\n166.09\n\n\nsum_24TR\nNaN",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#kurtosis",
    "href": "1-Issue-for-Decision-Making.html#kurtosis",
    "title": "1  Issue for Decision-Making",
    "section": "1.3 Kurtosis",
    "text": "1.3 Kurtosis\nKurtosis measures the heaviness of the tails of a data distribution relative to a normal distribution. It is defined mathematically as:\n\\(g_2 = \\left[ \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum \\left( \\frac{x_i - \\bar{x}}{\\sigma} \\right)^4 \\right] - \\frac{3(n-1)^2}{(n-2)(n-3)}\\)\nwhere:\n\n\\(( n )\\): Number of observations,\n\\(( x_i )\\): Individual data points,\n\\(( \\bar{x} )\\): Mean of the data,\n\\(( \\sigma )\\): Standard deviation of the data.\n\nA kurtosis of \\(( 0 )\\) (excess kurtosis) indicates tail behavior similar to a normal distribution. Positive kurtosis \\(( g_2 &gt; 0 )\\) signifies heavier tails and more outliers (leptokurtic), while negative kurtosis \\(( g_2 &lt; 0 )\\) indicates lighter tails and fewer outliers (platykurtic).\n\n# step by step\nz_fourth &lt;- z_scores^4\nsum_fourth &lt;- sum(z_fourth)\nkurtosis &lt;- ((n * (n + 1)) / ((n - 1) * (n - 2) * (n - 3))) * sum_fourth - (3 * (n - 1)^2) / ((n - 2) * (n - 3))\nprint(kurtosis)\n\n[1] 28577.97\n\n# function\nkurtosis(delitos_data$sum_24HP, na.rm = TRUE)\n\n[1] 28577.75\n\n# skewness\ndelitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  summarise(across(everything(), ~ kurtosis(.x, na.rm = TRUE))) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  mutate(V1 = round(V1, 2)) %&gt;%\n  rename(Skewness = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nSkewness\n\n\n\n\nsum_24HOM\n141.74\n\n\nsum_24LP\n27039.79\n\n\nsum_24VI\n31461.55\n\n\nsum_24DS\n28119.39\n\n\nsum_24HP\n28577.75\n\n\nsum_24HR\n8504.84\n\n\nsum_24HC\n23093.91\n\n\nsum_24HA\n256.92\n\n\nsum_24HM\n208.91\n\n\nsum_24SS\n22160.72\n\n\nsum_24SE\n22160.50\n\n\nsum_24EX\n30087.45\n\n\nsum_24TR\nNaN",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#coefficient-of-variation",
    "href": "1-Issue-for-Decision-Making.html#coefficient-of-variation",
    "title": "1  Issue for Decision-Making",
    "section": "1.4 Coefficient of Variation",
    "text": "1.4 Coefficient of Variation\nThe coefficient of variation (CV) measures the relative variability of a dataset, expressed as a percentage. It is defined mathematically as:\n\\(CV = \\left( \\frac{\\sigma}{\\bar{x}} \\right) \\times 100\\)\nwhere:\n\n\\(( \\sigma )\\): Standard deviation of the data,\n\\(( \\bar{x} )\\): Mean of the data.\n\nThe coefficient of variation is particularly useful for comparing the variability of datasets with different units or widely different means. A lower CV indicates less variability relative to the mean, while a higher CV indicates greater variability.\n\n# Compute statistics\nmean_val &lt;- mean(delitos_data$sum_24HP, na.rm = TRUE)\nprint(mean_val)\n\n[1] 1.650581\n\nstd_dev &lt;- sd(delitos_data$sum_24HP, na.rm = TRUE)\nprint(std_dev)\n\n[1] 36.16457\n\n# Compute the range for first standard deviation\nlower_bound &lt;- mean_val - std_dev\nupper_bound &lt;- mean_val + std_dev\npaste0('lower_bound: ', round(lower_bound, 2), ' - upper_bound: ', round(upper_bound, 2))\n\n[1] \"lower_bound: -34.51 - upper_bound: 37.82\"\n\n# Count the number of points within 1 standard deviation\nwithin_1sd &lt;- sum(delitos_data$sum_24HP &gt;= lower_bound & delitos_data$sum_24HP &lt;= upper_bound, na.rm = TRUE)\npercentage_1sd &lt;- (within_1sd / nrow(delitos_data)) * 100\npaste0('within_1sd: ', round(within_1sd, 2), ' - percentage_1sd: ', round(percentage_1sd, 2))\n\n[1] \"within_1sd: 44230 - percentage_1sd: 99.79\"\n\n# Create histogram\nggplot(delitos_data, aes(x = sum_24HP)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", alpha = 0.5, color = \"black\") +\n  \n  # Add vertical lines for mean, median, and 1st SD\n  geom_vline(aes(xintercept = mean_val), color = \"red\", linetype = \"dashed\", size = 1.2) +\n  #geom_vline(aes(xintercept = median_val), color = \"green\", linetype = \"dashed\", size = 1.2) +\n  geom_vline(aes(xintercept = lower_bound), color = \"purple\", linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = upper_bound), color = \"purple\", linetype = \"dashed\", size = 1) +\n  \n  # Labels and title\n  labs(title = \"Histogram of AUTOMOTORES with Mean, and 1SD Range\",\n       x = \"AUTOMOTORES Values\", y = \"Frequency\") +\n  \n  # Add annotation for 1SD range\n  annotate(\"text\", x = mean_val, y = 10, \n           label = paste(round(percentage_1sd, 2), \"% 1SD\", sep = \"\"), \n           color = \"black\", size = 5, hjust = 0.5, vjust = -1) +\n  \n  theme_minimal()\n\n\n\n\n\n\n\n# cv\npaste0('cv: ', round(std_dev / mean_val * 100), 2)\n\n[1] \"cv: 21912\"\n\n# variation\ndelitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  summarise(\n    across(\n      everything(),\n      ~ ifelse(mean(.x, na.rm = TRUE) != 0, \n               sd(.x, na.rm = TRUE) / mean(.x, na.rm = TRUE), \n               NA),  # Compute CV safely\n      .names = \"{col}\"\n    )\n  ) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  tibble::rownames_to_column(var = \"Crime Type\") %&gt;%\n  mutate(V1 = round(V1, 2)) %&gt;%\n  rename(Variation = V1) %&gt;%\n  gt()\n\n\n\n\n\n\n\nCrime Type\nVariation\n\n\n\n\nsum_24HOM\n8.61\n\n\nsum_24LP\n9.72\n\n\nsum_24VI\n20.76\n\n\nsum_24DS\n25.83\n\n\nsum_24HP\n21.91\n\n\nsum_24HR\n5.27\n\n\nsum_24HC\n14.76\n\n\nsum_24HA\n5.04\n\n\nsum_24HM\n4.51\n\n\nsum_24SS\n128.92\n\n\nsum_24SE\n148.87\n\n\nsum_24EX\n28.99\n\n\nsum_24TR\nNA",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#median-absolute-deviation-mad-and-madmedian",
    "href": "1-Issue-for-Decision-Making.html#median-absolute-deviation-mad-and-madmedian",
    "title": "1  Issue for Decision-Making",
    "section": "1.5 Median Absolute Deviation MAD and MAD/median",
    "text": "1.5 Median Absolute Deviation MAD and MAD/median\nThe Median Absolute Deviation (MAD) is a robust measure of variability that quantifies the dispersion of a dataset. It is defined as the median of the absolute deviations from the median of the data:\n\\(\\text{MAD} = \\text{median} \\left( \\left| x_i - \\text{median}(x) \\right| \\right)\\)\nwhere:\n\n( x_i ): Individual data points,\n( (x) ): Median of the data.\n\nThe MAD/Median ratio is a normalized measure of dispersion, calculated as:\n\\([\n\\text{MAD/Median} = \\frac{\\text{MAD}}{\\text{median}(x)}\n]\\)\nThis ratio provides a scale-independent measure of variability, making it useful for comparing the dispersion of datasets with different units or scales. A higher MAD/Median ratio indicates greater relative variability.\n\n# Compute statistics\nmedian_val &lt;- median(delitos_data$sum_24HP, na.rm = TRUE)\nprint(median_val)\n\n[1] 0\n\nmad_val &lt;- mad(delitos_data$sum_24HP, na.rm = TRUE)  # Compute MAD\nprint(mad_val)\n\n[1] 0\n\n# Compute the range for first standard deviation\nlower_bound &lt;- median_val - mad_val\nupper_bound &lt;- median_val + mad_val\npaste0('lower_bound: ', round(lower_bound, 2), ' - upper_bound: ', round(upper_bound, 2))\n\n[1] \"lower_bound: 0 - upper_bound: 0\"\n\n# Count the number of points within 1 MAD\nwithin_1mad &lt;- sum(delitos_data$sum_24HP &gt;= lower_bound & delitos_data$sum_24HP &lt;= upper_bound, na.rm = TRUE)\npercentage_1mad &lt;- (within_1mad / nrow(delitos_data)) * 100\npaste0('within_1mad: ', round(within_1mad, 2), ' - percentage_1mad: ', round(percentage_1mad, 2))\n\n[1] \"within_1mad: 24188 - percentage_1mad: 54.57\"\n\n# Create histogram\nggplot(delitos_data, aes(x = sum_24HP)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", alpha = 0.5, color = \"black\") +\n  \n  # Add vertical lines for mean, median, and 1st SD\n  #geom_vline(aes(xintercept = mean_val), color = \"red\", linetype = \"dashed\", size = 1.2) +\n  geom_vline(aes(xintercept = median_val), color = \"green\", linetype = \"dashed\", size = 1.2) +\n  geom_vline(aes(xintercept = lower_bound), color = \"purple\", linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = upper_bound), color = \"purple\", linetype = \"dashed\", size = 1) +\n  \n  # Labels and title\n  labs(title = \"Histogram of AUTOMOTORES with Median, and 1MAD Range\",\n       x = \"AUTOMOTORES Values\", y = \"Frequency\") +\n  \n  # Add annotation for 1SD range\n  annotate(\"text\", x = median_val, y = 10, \n           label = paste(within_1mad, \"points (\", round(percentage_1mad, 2), \"%) 1MAD\", sep = \"\"), \n           color = \"black\", size = 5, hjust = 0.5, vjust = -1) +\n  \n  theme_minimal()\n\n\n\n\n\n\n\n# MAD/Median\npaste0('MAD/Median: ', round(mad_val / median_val * 100), 2)\n\n[1] \"MAD/Median: NaN2\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#import-dataset-load-required-packages-and-provide-a-summary",
    "href": "1-Issue-for-Decision-Making.html#import-dataset-load-required-packages-and-provide-a-summary",
    "title": "1  Issue for Decision-Making",
    "section": "1.1 Import Dataset, Load Required Packages, and Provide a Summary",
    "text": "1.1 Import Dataset, Load Required Packages, and Provide a Summary\n\n# working directory\n#setwd(dirname(rstudioapi::getSourceEditorContext()$path))\n\n# packages\nlist_packages = c('readxl', 'dplyr', 'moments', 'tidyr', 'tibble', 'gt', 'ggplot2', 'fmsb', 'car', 'reshape2', 'knitr', 'gridExtra', 'ggExtra', 'sf')\nnew.packages = list_packages[!(list_packages %in% installed.packages()[,\"Package\"])]\nif (length(new.packages)) {\n  install.packages(new.packages)\n}\nfor (package in list_packages){\n  library(package, character.only = T)\n}\n\n# Load the dataset\ndelitos_data &lt;- st_read(\"data/spatial/crime_spatial_course.gpkg\")\n\nReading layer `crime_spatial_course' from data source \n  `/Users/andresperezcoronado/Documents/GitHub/Advanced-data-analytics-course/Advance analytics course/data/spatial/crime_spatial_course.gpkg' \n  using driver `GPKG'\nSimple feature collection with 528690 features and 90 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -81.73271 ymin: -4.226476 xmax: -66.96209 ymax: 13.38684\nGeodetic CRS:  MAGNA-SIRGAS\n\ndelitos_data &lt;- delitos_data[delitos_data$dpto_ccdgo == '11', ]\n\ndim(delitos_data)\n\n[1] 44325    91\n\nsummary(delitos_data)\n\n  dpto_ccdgo         mpio_ccdgo         mpio_cdpmp         clas_ccdgo       \n Length:44325       Length:44325       Length:44325       Length:44325      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  setr_ccdgo         setr_ccnct         secr_ccdgo         secr_ccnct       \n Length:44325       Length:44325       Length:44325       Length:44325      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   zu_ccdgo           zu_cdivi          setu_ccdgo         setu_ccnct       \n Length:44325       Length:44325       Length:44325       Length:44325      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  secu_ccdgo         secu_ccnct         manz_ccdgo         manz_ccnct       \n Length:44325       Length:44325       Length:44325       Length:44325      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   manz_cag          tipo_ctstr         cod_ctstr           manz_nano   \n Length:44325       Length:44325       Length:44325       Min.   :2023  \n Class :character   Class :character   Class :character   1st Qu.:2023  \n Mode  :character   Mode  :character   Mode  :character   Median :2023  \n                                                          Mean   :2023  \n                                                          3rd Qu.:2023  \n                                                          Max.   :2023  \n   manz_nid           manz_nfe          manz_tipo          fuen_actlz       \n Length:44325       Length:44325       Length:44325       Length:44325      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  tipo_imgn           ano_fuente        tipo_actlz          ano_actlz       \n Length:44325       Min.   :   0.000   Length:44325       Min.   :   0.000  \n Class :character   1st Qu.:   0.000   Class :character   1st Qu.:   0.000  \n Mode  :character   Median :   0.000   Mode  :character   Median :   0.000  \n                    Mean   :   2.599                      Mean   :   2.602  \n                    3rd Qu.:   0.000                      3rd Qu.:   0.000  \n                    Max.   :2023.000                      Max.   :2023.000  \n  revi_campo          manz_narea        manz_lati       manz_long     \n Length:44325       Min.   :     32   Min.   :3.889   Min.   :-74.36  \n Class :character   1st Qu.:   1464   1st Qu.:4.567   1st Qu.:-74.15  \n Mode  :character   Median :   2602   Median :4.617   Median :-74.11  \n                    Mean   :   7221   Mean   :4.624   Mean   :-74.12  \n                    3rd Qu.:   5131   3rd Qu.:4.684   3rd Qu.:-74.09  \n                    Max.   :9064324   Max.   :4.826   Max.   :-74.01  \n   shape_Leng           MANZ_VIV        FT_ACT_VIV          Shape_Le_1       \n Min.   :0.0002113   Min.   :   0.00   Length:44325       Min.   :0.0002113  \n 1st Qu.:0.0015639   1st Qu.:  15.00   Class :character   1st Qu.:0.0015639  \n Median :0.0021673   Median :  34.00   Mode  :character   Median :0.0021673  \n Mean   :0.0027577   Mean   :  54.52                      Mean   :0.0027577  \n 3rd Qu.:0.0029981   3rd Qu.:  58.00                      3rd Qu.:0.0029981  \n Max.   :0.1441678   Max.   :3431.00                      Max.   :0.1441678  \n   Shape_Area           ID_unico        sum_22HOM         sum_23HOM      \n Min.   :2.600e-09   Min.   :   916   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:1.193e-07   1st Qu.:125383   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :2.120e-07   Median :257838   Median :0.00000   Median :0.00000  \n Mean   :5.885e-07   Mean   :257634   Mean   :0.01324   Mean   :0.01313  \n 3rd Qu.:4.182e-07   3rd Qu.:383914   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :7.388e-04   Max.   :521986   Max.   :4.00000   Max.   :4.00000  \n   sum_24HOM         sum_25HOM           sum_22LP          sum_23LP       \n Min.   :0.00000   Min.   :0.000000   Min.   : 0.0000   Min.   :  0.0000  \n 1st Qu.:0.00000   1st Qu.:0.000000   1st Qu.: 0.0000   1st Qu.:  0.0000  \n Median :0.00000   Median :0.000000   Median : 0.0000   Median :  0.0000  \n Mean   :0.01647   Mean   :0.001376   Mean   : 0.2727   Mean   :  0.2259  \n 3rd Qu.:0.00000   3rd Qu.:0.000000   3rd Qu.: 0.0000   3rd Qu.:  0.0000  \n Max.   :4.00000   Max.   :2.000000   Max.   :66.0000   Max.   :587.0000  \n    sum_24LP           sum_25LP           sum_22VI           sum_23VI       \n Min.   :  0.0000   Min.   : 0.00000   Min.   :  0.0000   Min.   :  0.0000  \n 1st Qu.:  0.0000   1st Qu.: 0.00000   1st Qu.:  0.0000   1st Qu.:  0.0000  \n Median :  0.0000   Median : 0.00000   Median :  0.0000   Median :  0.0000  \n Mean   :  0.2642   Mean   : 0.01875   Mean   :  0.5175   Mean   :  0.4369  \n 3rd Qu.:  0.0000   3rd Qu.: 0.00000   3rd Qu.:  1.0000   3rd Qu.:  0.0000  \n Max.   :477.0000   Max.   :12.00000   Max.   :272.0000   Max.   :850.0000  \n    sum_24VI            sum_25VI           sum_22DS           sum_23DS       \n Min.   :   0.0000   Min.   : 0.00000   Min.   : 0.00000   Min.   :  0.0000  \n 1st Qu.:   0.0000   1st Qu.: 0.00000   1st Qu.: 0.00000   1st Qu.:  0.0000  \n Median :   0.0000   Median : 0.00000   Median : 0.00000   Median :  0.0000  \n Mean   :   0.7304   Mean   : 0.04014   Mean   : 0.09891   Mean   :  0.0768  \n 3rd Qu.:   1.0000   3rd Qu.: 0.00000   3rd Qu.: 0.00000   3rd Qu.:  0.0000  \n Max.   :2915.0000   Max.   :88.00000   Max.   :98.00000   Max.   :367.0000  \n    sum_24DS           sum_25DS           sum_22HP          sum_23HP       \n Min.   :  0.0000   Min.   :0.000000   Min.   :  0.000   Min.   :   0.000  \n 1st Qu.:  0.0000   1st Qu.:0.000000   1st Qu.:  0.000   1st Qu.:   0.000  \n Median :  0.0000   Median :0.000000   Median :  0.000   Median :   1.000  \n Mean   :  0.1428   Mean   :0.004557   Mean   :  1.632   Mean   :   1.729  \n 3rd Qu.:  0.0000   3rd Qu.:0.000000   3rd Qu.:  2.000   3rd Qu.:   2.000  \n Max.   :682.0000   Max.   :6.000000   Max.   :468.000   Max.   :3111.000  \n    sum_24HP           sum_25HP            sum_22HR          sum_23HR       \n Min.   :   0.000   Min.   :  0.00000   Min.   : 0.0000   Min.   : 0.00000  \n 1st Qu.:   0.000   1st Qu.:  0.00000   1st Qu.: 0.0000   1st Qu.: 0.00000  \n Median :   0.000   Median :  0.00000   Median : 0.0000   Median : 0.00000  \n Mean   :   1.651   Mean   :  0.09487   Mean   : 0.1022   Mean   : 0.09877  \n 3rd Qu.:   1.000   3rd Qu.:  0.00000   3rd Qu.: 0.0000   3rd Qu.: 0.00000  \n Max.   :6737.000   Max.   :141.00000   Max.   :20.0000   Max.   :88.00000  \n    sum_24HR           sum_25HR           sum_22HC           sum_23HC       \n Min.   : 0.00000   Min.   :0.000000   Min.   :  0.0000   Min.   :  0.0000  \n 1st Qu.: 0.00000   1st Qu.:0.000000   1st Qu.:  0.0000   1st Qu.:  0.0000  \n Median : 0.00000   Median :0.000000   Median :  0.0000   Median :  0.0000  \n Mean   : 0.09385   Mean   :0.006836   Mean   :  0.1587   Mean   :  0.1381  \n 3rd Qu.: 0.00000   3rd Qu.:0.000000   3rd Qu.:  0.0000   3rd Qu.:  0.0000  \n Max.   :68.00000   Max.   :8.000000   Max.   :137.0000   Max.   :242.0000  \n    sum_24HC           sum_25HC          sum_22HA          sum_23HA       \n Min.   :  0.0000   Min.   :0.00000   Min.   :0.00000   Min.   : 0.00000  \n 1st Qu.:  0.0000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.: 0.00000  \n Median :  0.0000   Median :0.00000   Median :0.00000   Median : 0.00000  \n Mean   :  0.1552   Mean   :0.00564   Mean   :0.04566   Mean   : 0.05214  \n 3rd Qu.:  0.0000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.: 0.00000  \n Max.   :407.0000   Max.   :6.00000   Max.   :7.00000   Max.   :16.00000  \n    sum_24HA           sum_25HA           sum_22HM          sum_23HM       \n Min.   : 0.00000   Min.   :0.000000   Min.   :0.00000   Min.   : 0.00000  \n 1st Qu.: 0.00000   1st Qu.:0.000000   1st Qu.:0.00000   1st Qu.: 0.00000  \n Median : 0.00000   Median :0.000000   Median :0.00000   Median : 0.00000  \n Mean   : 0.05462   Mean   :0.002798   Mean   :0.06279   Mean   : 0.07343  \n 3rd Qu.: 0.00000   3rd Qu.:0.000000   3rd Qu.:0.00000   3rd Qu.: 0.00000  \n Max.   :15.00000   Max.   :1.000000   Max.   :7.00000   Max.   :32.00000  \n    sum_24HM           sum_25HM           sum_22SS            sum_23SS       \n Min.   : 0.00000   Min.   :0.000000   Min.   :0.0000000   Min.   :0.00e+00  \n 1st Qu.: 0.00000   1st Qu.:0.000000   1st Qu.:0.0000000   1st Qu.:0.00e+00  \n Median : 0.00000   Median :0.000000   Median :0.0000000   Median :0.00e+00  \n Mean   : 0.07377   Mean   :0.004061   Mean   :0.0001128   Mean   :2.26e-05  \n 3rd Qu.: 0.00000   3rd Qu.:0.000000   3rd Qu.:0.0000000   3rd Qu.:0.00e+00  \n Max.   :16.00000   Max.   :2.000000   Max.   :2.0000000   Max.   :1.00e+00  \n    sum_24SS           sum_25SS    sum_22SE            sum_23SE        \n Min.   :0.00e+00   Min.   :0   Min.   :0.0000000   Min.   :0.0000000  \n 1st Qu.:0.00e+00   1st Qu.:0   1st Qu.:0.0000000   1st Qu.:0.0000000  \n Median :0.00e+00   Median :0   Median :0.0000000   Median :0.0000000  \n Mean   :9.02e-05   Mean   :0   Mean   :0.0001805   Mean   :0.0001128  \n 3rd Qu.:0.00e+00   3rd Qu.:0   3rd Qu.:0.0000000   3rd Qu.:0.0000000  \n Max.   :2.00e+00   Max.   :0   Max.   :3.0000000   Max.   :2.0000000  \n    sum_24SE           sum_25SE    sum_22EX           sum_23EX       \n Min.   :0.00e+00   Min.   :0   Min.   : 0.00000   Min.   : 0.00000  \n 1st Qu.:0.00e+00   1st Qu.:0   1st Qu.: 0.00000   1st Qu.: 0.00000  \n Median :0.00e+00   Median :0   Median : 0.00000   Median : 0.00000  \n Mean   :4.51e-05   Mean   :0   Mean   : 0.01814   Mean   : 0.01839  \n 3rd Qu.:0.00e+00   3rd Qu.:0   3rd Qu.: 0.00000   3rd Qu.: 0.00000  \n Max.   :1.00e+00   Max.   :0   Max.   :22.00000   Max.   :79.00000  \n    sum_24EX            sum_25EX           sum_22TR           sum_23TR\n Min.   :  0.00000   Min.   :0.000000   Min.   :0.00e+00   Min.   :0  \n 1st Qu.:  0.00000   1st Qu.:0.000000   1st Qu.:0.00e+00   1st Qu.:0  \n Median :  0.00000   Median :0.000000   Median :0.00e+00   Median :0  \n Mean   :  0.04151   Mean   :0.001805   Mean   :2.26e-05   Mean   :0  \n 3rd Qu.:  0.00000   3rd Qu.:0.000000   3rd Qu.:0.00e+00   3rd Qu.:0  \n Max.   :228.00000   Max.   :6.000000   Max.   :1.00e+00   Max.   :0  \n    sum_24TR    sum_25TR            geom      \n Min.   :0   Min.   :0   POLYGON      :44325  \n 1st Qu.:0   1st Qu.:0   epsg:4686    :    0  \n Median :0   Median :0   +proj=long...:    0  \n Mean   :0   Mean   :0                        \n 3rd Qu.:0   3rd Qu.:0                        \n Max.   :0   Max.   :0                        \n\nplot(delitos_data$geo)\n\n\n\n\n\n\n\n# quantile\nquantile(delitos_data$sum_24HP, probs = seq(0, 1, 0.1), na.rm = TRUE)\n\n  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n   0    0    0    0    0    0    1    1    2    3 6737 \n\n#boxplot\nboxplot(delitos_data$sum_24HP, main = \"Boxplot of PERSONAS\", horizontal = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#distribution-of-crime-data",
    "href": "1-Issue-for-Decision-Making.html#distribution-of-crime-data",
    "title": "1  Issue for Decision-Making",
    "section": "1.11 Distribution of Crime Data",
    "text": "1.11 Distribution of Crime Data\n\n# Load necessary library\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Transform the data to a long format for ggplot\ndelitos_long &lt;- delitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%  # Select only numeric columns\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Value\")\n\n# Create faceted histograms\nggplot(delitos_long, aes(x = Value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Distributions of Crime Data\",\n    x = \"Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 5)  # Reduce the font size of X-axis text\n  )",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#log-transformed-crime-data-distributions",
    "href": "1-Issue-for-Decision-Making.html#log-transformed-crime-data-distributions",
    "title": "1  Issue for Decision-Making",
    "section": "1.12 Log-Transformed Crime Data Distributions",
    "text": "1.12 Log-Transformed Crime Data Distributions\n\n# Transform the data to long format and apply log transformation\ndelitos_long_log &lt;- delitos_data %&gt;%\n  select(where(is.numeric)) %&gt;%\n  mutate(across(everything(), ~ log(.x), .names = \"{col}\")) %&gt;%  # Log transform (log(x + 1) to avoid log(0))\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Log Value\")\n\n# Create faceted histograms for log-transformed values\nggplot(delitos_long_log, aes(x = `Log Value`)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Log-Transformed Distributions of Crime Data\",\n    x = \"Log Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 3)  # Reduce the font size of X-axis text\n  )",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#covariance-matrix",
    "href": "1-Issue-for-Decision-Making.html#covariance-matrix",
    "title": "1  Issue for Decision-Making",
    "section": "1.6 Covariance Matrix",
    "text": "1.6 Covariance Matrix\nThe covariance matrix \\(( \\Sigma )\\) captures the pairwise covariances between variables in a dataset. For a dataset \\(( X )\\) with \\(( n )\\) observations and \\(( p )\\) variables, the covariance matrix is defined as:\n\\(\\Sigma = \\frac{1}{n-1} (X - \\bar{X})^\\top (X - \\bar{X})\\)\nwhere:\n\n\\(( X )\\) is the \\(( n \\times p )\\) data matrix.\n\\(( \\bar{X} )\\) is the \\(( n \\times p )\\) matrix of column means.\n\\(( \\Sigma )\\) is a \\(( p \\times p )\\) symmetric matrix.\n\n\ndelitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains(\"24\")) %&gt;%\n  cov() %&gt;%\n  round(2) %&gt;%\n  knitr::kable(digits = 2, caption = \"Covariance Matrix\")\n\n\nCovariance Matrix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsum_24HOM\nsum_24LP\nsum_24VI\nsum_24DS\nsum_24HP\nsum_24HR\nsum_24HC\nsum_24HA\nsum_24HM\nsum_24SS\nsum_24SE\nsum_24EX\nsum_24TR\n\n\n\n\nsum_24HOM\n0.02\n0.02\n0.10\n0.02\n0.20\n0.00\n0.01\n0.00\n0.00\n0\n0\n0.01\n0\n\n\nsum_24LP\n0.02\n6.60\n36.36\n8.75\n86.03\n0.89\n5.07\n0.21\n0.27\n0\n0\n2.83\n0\n\n\nsum_24VI\n0.10\n36.36\n229.97\n54.70\n530.02\n5.48\n30.98\n1.13\n1.51\n0\n0\n17.58\n0\n\n\nsum_24DS\n0.02\n8.75\n54.70\n13.60\n130.25\n1.34\n7.57\n0.26\n0.36\n0\n0\n4.31\n0\n\n\nsum_24HP\n0.20\n86.03\n530.02\n130.25\n1307.88\n13.24\n75.95\n2.73\n3.61\n0\n0\n42.17\n0\n\n\nsum_24HR\n0.00\n0.89\n5.48\n1.34\n13.24\n0.24\n0.77\n0.03\n0.04\n0\n0\n0.43\n0\n\n\nsum_24HC\n0.01\n5.07\n30.98\n7.57\n75.95\n0.77\n5.24\n0.17\n0.22\n0\n0\n2.47\n0\n\n\nsum_24HA\n0.00\n0.21\n1.13\n0.26\n2.73\n0.03\n0.17\n0.08\n0.02\n0\n0\n0.09\n0\n\n\nsum_24HM\n0.00\n0.27\n1.51\n0.36\n3.61\n0.04\n0.22\n0.02\n0.11\n0\n0\n0.11\n0\n\n\nsum_24SS\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0\n0\n0.00\n0\n\n\nsum_24SE\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0\n0\n0.00\n0\n\n\nsum_24EX\n0.01\n2.83\n17.58\n4.31\n42.17\n0.43\n2.47\n0.09\n0.11\n0\n0\n1.45\n0\n\n\nsum_24TR\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0\n0\n0.00\n0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#covariance-matrix-of-log-transformed-data",
    "href": "1-Issue-for-Decision-Making.html#covariance-matrix-of-log-transformed-data",
    "title": "1  Issue for Decision-Making",
    "section": "1.7 Covariance Matrix of Log-Transformed Data",
    "text": "1.7 Covariance Matrix of Log-Transformed Data\nTo handle skewed data or reduce the impact of outliers, we apply a log transformation to the data. Let \\(( Y = \\log(X + 1) )\\), where \\(( \\log )\\) is applied element-wise and \\(( 1 )\\) is a matrix of ones to handle zeros. The log-transformed covariance matrix \\(( \\Sigma_{\\text{log}} )\\) is:\n\\(\\Sigma_{\\text{log}} = \\frac{1}{n-1} (Y - \\bar{Y})^\\top (Y - \\bar{Y})\\)\nwhere:\n\n\\(( Y )\\) is the \\(( n \\times p )\\) log-transformed data matrix.\n\\(( \\bar{Y} )\\) is the \\(( n \\times p )\\) matrix of column means of \\(( Y )\\).\n\nWe are going to begin by understanding log transformation, a key tool for handling multiplicative relationships in data.\n\nCompresses large values to reduce skewness.\nConverts multiplicative relationships into additive ones.\nEases interpretation when values span multiple orders of magnitude.\n\n\n# Define the dataset\nx &lt;- delitos_data$sum_24HP\n\n# 1. Compute Raw Arithmetic Mean\narithmetic_mean &lt;- mean(x)\nprint(arithmetic_mean)\n\n[1] 1.650581\n\n# 2. Compute Log-Mean (Multiplicative Center)\nlog_x &lt;- log(x + 1)  # Take logarithm of values\nhead(log_x)\n\n[1] 0.0000000 1.3862944 0.6931472 0.0000000 0.0000000 0.0000000\n\nlog_mean &lt;- mean(log_x)  # Compute mean in log-space\nprint(log_mean)\n\n[1] 0.5134252\n\nlog_mean_exp &lt;- exp(log_mean)  # Convert back to original scale\nprint(log_mean_exp)\n\n[1] 1.671005\n\n# Create the comparison table\ncomparison_table &lt;- data.frame(\n  Index = seq_along(x),  # Just an index for x-axis\n  Original_Value = x,\n  Log_Value = log_x\n)\n\np1 &lt;- ggplot(comparison_table, aes(x = Original_Value, y = Log_Value)) +\n  geom_line(color = \"gray70\", size = 0.7, alpha = 0.5) +  # Thin line connecting points\n  geom_point(alpha = 0.7, color = \"blue\") +  # Scatter points with transparency\n  labs(\n    title = \"Scatter Plot: Original vs. Log-Transformed Values\",\n    x = \"Original Values\",\n    y = \"Log-Transformed Values\"\n  ) +\n  theme_minimal()\n\n# Add marginal histogram\nggMarginal(\n  p1,\n  type = \"histogram\",         # Add marginal histograms\n  bins = 40,                  # Number of bins for the histogram\n  margins = \"both\",           # Add histogram to both x and y margins\n  size = 5,                   # Size of the histograms relative to the scatter plot\n  fill = \"gray\",              # Fill color for the histogram\n  color = \"black\",            # Outline color for the histogram\n  alpha = 0.5                 # Transparency\n)\n\n\n\n\n\n\n\n\nEuler steps describe how many multiplicative steps of \\(( e )\\) are needed to reach a given value.\nFor example, in our dataset:\n\nOriginal Values: 0, 3, 1, 0, 0, 0\n\nLog Values: 0, 1.39, 0.69, 0, 0, 0\n\nEach log-transformed value represents the number of times we need to multiply 1 by \\(( e )\\) to reach the original value:\n\\(e^ \\text{Log Values} = \\text{Original Value}\\)\n\n#log transformed data\n# Compute statistics for raw and log-transformed data\nmean_raw &lt;- mean(delitos_data$sum_24HP, na.rm = TRUE)\nsd_raw &lt;- sd(delitos_data$sum_24HP, na.rm = TRUE)\nmad_raw &lt;- mad(delitos_data$sum_24HP, na.rm = TRUE)\n\ndelitos_data_log &lt;- delitos_data %&gt;%\n  #mutate(LOG_AUTOMOTORES = log(AUTOMOTORES + 1))\n  mutate(LOG_AUTOMOTORES = log1p(sum_24HP))  # log1p(x) = log(1 + x) to handle zeros\n\nmean_log &lt;- mean(delitos_data_log$LOG_AUTOMOTORES, na.rm = TRUE)\nsd_log &lt;- sd(delitos_data_log$LOG_AUTOMOTORES, na.rm = TRUE)\nmad_log &lt;- mad(delitos_data_log$LOG_AUTOMOTORES, na.rm = TRUE)\n\n# Compute statistics for raw and log-transformed data\ndata.frame(\n  Measure = c(\"Mean\", \"Median\", \"Standard Deviation\", \"MAD\"),\n  Raw_Data = c(mean(delitos_data$sum_24HP, na.rm = TRUE),\n               median(delitos_data$sum_24HP, na.rm = TRUE),\n               sd(delitos_data$sum_24HP, na.rm = TRUE),\n               mad(delitos_data$sum_24HP, na.rm = TRUE)),\n  Log_Transformed_Data = c(mean(delitos_data_log$LOG_AUTOMOTORES, na.rm = TRUE),\n                           median(delitos_data_log$LOG_AUTOMOTORES, na.rm = TRUE),\n                           sd(delitos_data_log$LOG_AUTOMOTORES, na.rm = TRUE),\n                           mad(delitos_data_log$LOG_AUTOMOTORES, na.rm = TRUE)))\n\n             Measure  Raw_Data Log_Transformed_Data\n1               Mean  1.650581            0.5134252\n2             Median  0.000000            0.0000000\n3 Standard Deviation 36.164573            0.6903587\n4                MAD  0.000000            0.0000000\n\n# Transform the data to a long format for ggplot\ndelitos_long &lt;- delitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Value\")\n\n# Create faceted histograms\nggplot(delitos_long, aes(x = Value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Distributions of Crime Data\",\n    x = \"Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 5)  # Reduce the font size of X-axis text\n  )\n\n\n\n\n\n\n\n# Transform the data to long format and apply log transformation\ndelitos_long_log &lt;- delitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  mutate(across(everything(), ~ log(.x), .names = \"{col}\")) %&gt;%  # Log transform (log(x + 1) to avoid log(0))\n  pivot_longer(cols = everything(), names_to = \"Crime Type\", values_to = \"Log Value\")\n\n# Create faceted histograms for log-transformed values\nggplot(delitos_long_log, aes(x = `Log Value`)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  facet_wrap(~ `Crime Type`, scales = \"free\") +  # Facet by crime type\n  theme_minimal() +\n  labs(\n    title = \"Log-Transformed Distributions of Crime Data\",\n    x = \"Log Value\",\n    y = \"Frequency\"\n  ) +\n  theme(\n    axis.text.x = element_text(size = 3)  # Reduce the font size of X-axis text\n  )\n\n\n\n\n\n\n\n# Covariance Matrix (Log-Transformed)\ndelitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  mutate(across(everything(), ~ log(.x+1))) %&gt;%  # Log-transform (+1 to handle zeros)\n  cov() %&gt;%\n  round(2) %&gt;%\n  kable(digits = 2, caption = \"Covariance Matrix (Log-Transformed)\")\n\n\nCovariance Matrix (Log-Transformed)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsum_24HOM\nsum_24LP\nsum_24VI\nsum_24DS\nsum_24HP\nsum_24HR\nsum_24HC\nsum_24HA\nsum_24HM\nsum_24SS\nsum_24SE\nsum_24EX\nsum_24TR\n\n\n\n\nsum_24HOM\n0.01\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0\n0\n0.00\n0\n\n\nsum_24LP\n0.00\n0.12\n0.05\n0.02\n0.08\n0.01\n0.02\n0.01\n0.01\n0\n0\n0.01\n0\n\n\nsum_24VI\n0.00\n0.05\n0.27\n0.03\n0.09\n0.02\n0.02\n0.01\n0.02\n0\n0\n0.01\n0\n\n\nsum_24DS\n0.00\n0.02\n0.03\n0.06\n0.04\n0.01\n0.01\n0.00\n0.01\n0\n0\n0.00\n0\n\n\nsum_24HP\n0.00\n0.08\n0.09\n0.04\n0.48\n0.03\n0.07\n0.02\n0.03\n0\n0\n0.02\n0\n\n\nsum_24HR\n0.00\n0.01\n0.02\n0.01\n0.03\n0.04\n0.01\n0.00\n0.00\n0\n0\n0.00\n0\n\n\nsum_24HC\n0.00\n0.02\n0.02\n0.01\n0.07\n0.01\n0.07\n0.00\n0.01\n0\n0\n0.01\n0\n\n\nsum_24HA\n0.00\n0.01\n0.01\n0.00\n0.02\n0.00\n0.00\n0.03\n0.00\n0\n0\n0.00\n0\n\n\nsum_24HM\n0.00\n0.01\n0.02\n0.01\n0.03\n0.00\n0.01\n0.00\n0.04\n0\n0\n0.00\n0\n\n\nsum_24SS\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0\n0\n0.00\n0\n\n\nsum_24SE\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0\n0\n0.00\n0\n\n\nsum_24EX\n0.00\n0.01\n0.01\n0.00\n0.02\n0.00\n0.01\n0.00\n0.00\n0\n0\n0.02\n0\n\n\nsum_24TR\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0\n0\n0.00\n0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#global-variability-metric",
    "href": "1-Issue-for-Decision-Making.html#global-variability-metric",
    "title": "1  Issue for Decision-Making",
    "section": "1.9 Global Variability Metric",
    "text": "1.9 Global Variability Metric\nThe effective variance and effective standard deviation are measures of the overall variability in the dataset. They are derived from the determinant of the covariance matrix, which captures the generalized variance of the data. For log-transformed data, these metrics are computed similarly but on the log-transformed covariance matrix.\nThe effective variance is defined as:\nEffective Variance \\(= \\det(\\Sigma)^{\\frac{1}{p}}\\)\nwhere:\n\n\\(( \\Sigma )\\) is the covariance matrix.\n\\(( p )\\) is the number of variables.\n\nThe effective standard deviation is given by:\n\nEffective Standard Deviation \\(= \\det(\\Sigma)^{\\frac{1}{2p}}\\)\n\nFor log-transformed data, the effective variance is computed as:\n\nLog-Transformed Effective Variance \\(= \\det(\\log(\\Sigma + 1))^{\\frac{1}{p}}\\)\n\nSimilarly, the log-transformed effective standard deviation is:\n\nLog-Transformed Effective Standard Deviation \\(= \\det(\\log(\\Sigma + 1))^{\\frac{1}{2p}}\\)\n\n\ncov_matrix &lt;- delitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  select(-sum_24TR, -sum_24SE, -sum_24SS) %&gt;%\n  select(where(is.numeric)) %&gt;%  # Select numeric columns\n  cov() \n\n# Effective Variance\ndet(cov_matrix)^(1/ncol(cov_matrix))\n\n[1] 0.5881951\n\n# Log-Transformed Effective Variance\ndet(log(cov_matrix + 1))^(1/ncol(cov_matrix))\n\n[1] 0.1966575\n\n# Effective Standard Deviation\ndet(cov_matrix)^(1/(ncol(cov_matrix) * 2))\n\n[1] 0.7669388\n\n# Log-Transformed Effective Standard Deviation\ndet(log(cov_matrix + 1))^(1/(ncol(cov_matrix) * 2))\n\n[1] 0.4434608",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#redundant-variables",
    "href": "1-Issue-for-Decision-Making.html#redundant-variables",
    "title": "1  Issue for Decision-Making",
    "section": "1.8 Redundant Variables",
    "text": "1.8 Redundant Variables\nRedundant variables provide little additional information due to high correlation with others, leading to multicollinearity in models.\nMathematically, redundancy is detected using the covariance matrix \\(\\Sigma\\), whose eigenvalues \\(\\lambda_i\\) and eigenvectors \\(v_i\\) capture variance directions. A small eigenvalue \\(\\lambda_{\\min} \\approx 0\\) suggests a near-linear dependency:\n\\(\\Sigma v_{\\min} = \\lambda_{\\min} v_{\\min}\\)\nThe eigenvector \\(v_{\\\\min}\\) identifies the redundant variable combination.\nTo confirm, we fit a regression model where one variable \\(y\\) is explained by others:\n\\(y = \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\epsilon\\)\nTo quantify redundancy, we compute Variance Inflation Factors (VIFs) for each predictor \\(x_j\\):\n\\(VIF_j = \\frac{1}{1 - R_j^2}\\)\nwhere \\(R_j^2\\) is the \\(R^2\\) value from regressing \\(x_j\\) on all other predictors.\n\n\\(VIF_j = 1\\) → No multicollinearity.\n\n\\(VIF_j &gt; 5\\) → Moderate multicollinearity.\n\n\\(VIF_j &gt; 10\\) → Severe multicollinearity, indicating redundancy.\n\nA high VIF suggests that \\(x_j\\) contributes little independent information and may be removed to improve model stability.\nEigenvalues and eigenvectors are fundamental tools in linear algebra, representing the directions and scaling factors of a matrix transformation.\n\nEigenvalues: Solving the Characteristic Equation\n\nThe eigenvalues \\(( \\lambda )\\) of a matrix \\(( A )\\) satisfy:\n\\(\\det(A - \\lambda I) = 0\\)\nWhere: - \\(( A )\\) is the matrix. - \\(( \\lambda )\\) is the eigenvalue (unknown). - \\(( I )\\) is the identity matrix (a diagonal matrix with 1s on the diagonal).\nThe characteristic polynomial is derived by computing \\(( \\det(A - \\lambda I) )\\) and solving for \\(( \\lambda )\\).\nEigenvectors: Solving for Principal Directions\nFor each eigenvalue \\(( \\lambda )\\), the eigenvector \\(( v )\\) satisfies:\n\\((A - \\lambda I)v = 0\\)\nThis is a homogeneous system of linear equations. Solving this system gives the eigenvector(s) associated with each eigenvalue.\n\n# Define the matrix A\nmatrix_a &lt;- matrix(c(4, 2,\n                     2, 3), nrow = 2, byrow = TRUE)\nprint(\"Matrix A:\")\n\n[1] \"Matrix A:\"\n\nprint(matrix_a)\n\n     [,1] [,2]\n[1,]    4    2\n[2,]    2    3\n\n# Compute the eigen decomposition using R's built-in eigen() function\neigen_builtin &lt;- eigen(matrix_a)\nprint(\"Built-in eigen() values:\")\n\n[1] \"Built-in eigen() values:\"\n\nprint(eigen_builtin$values)\n\n[1] 5.561553 1.438447\n\nprint(\"Built-in eigen() vectors:\")\n\n[1] \"Built-in eigen() vectors:\"\n\nprint(eigen_builtin$vectors)\n\n           [,1]       [,2]\n[1,] -0.7882054  0.6154122\n[2,] -0.6154122 -0.7882054\n\n# Multiply A by the matrix of eigenvectors:\n# Each column of eigen_builtin$vectors is an eigenvector.\nres &lt;- matrix_a %*% eigen_builtin$vectors\nprint(\"A * eigenvectors:\")\n\n[1] \"A * eigenvectors:\"\n\nprint(res)\n\n          [,1]      [,2]\n[1,] -4.383646  0.885238\n[2,] -3.422648 -1.133792\n\n# Multiply the eigenvector matrix by the diagonal matrix of eigenvalues.\nres2 &lt;- eigen_builtin$vectors %*% diag(eigen_builtin$values)\nprint(\"eigenvectors * eigenvalues:\")\n\n[1] \"eigenvectors * eigenvalues:\"\n\nprint(res2)\n\n          [,1]      [,2]\n[1,] -4.383646  0.885238\n[2,] -3.422648 -1.133792\n\n# Check if these two matrices are equal (they should be equal within numerical precision)\nare_equal &lt;- all.equal(res, res2)\nprint(\"Are A * eigenvectors and eigenvectors * eigenvalues equal?\")\n\n[1] \"Are A * eigenvectors and eigenvectors * eigenvalues equal?\"\n\nprint(are_equal)\n\n[1] TRUE\n\n\n\n# Covariance matrix \ncm_delitos_data &lt;- delitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  #select(-sum_24TR, -sum_24SE, -sum_24SS) %&gt;%\n  cov()\n\n# Compute eigenvalues and eigenvectors\neigen_results &lt;- cm_delitos_data %&gt;% eigen()\n\n# Extract eigenvalues and eigenvectors\neigenvalues &lt;- eigen_results$values\neigenvectors &lt;- eigen_results$vectors\n\n# Display eigenvalues and eigenvectors\nprint(eigenvalues)\n\n [1] 1.549582e+03 1.324028e+01 8.638950e-01 7.526465e-01 3.891474e-01\n [6] 1.141914e-01 9.892545e-02 6.567150e-02 6.474194e-02 1.988079e-02\n[11] 1.350442e-04 4.470332e-05 0.000000e+00\n\nhead(eigenvectors)\n\n              [,1]         [,2]         [,3]         [,4]         [,5]\n[1,] -0.0001464551 -0.001102811  0.006313814 -0.008525117 -0.004105664\n[2,] -0.0608000936 -0.084368511  0.542164420 -0.831583105  0.018744697\n[3,] -0.3758945662 -0.911671856 -0.058887075  0.078998143 -0.132956669\n[4,] -0.0919350072 -0.098874710 -0.062756621 -0.001108157  0.978087734\n[5,] -0.9179995071  0.389042513 -0.054612038 -0.008730045 -0.052091037\n[6,] -0.0093230829 -0.004272469  0.006667796 -0.010152824  0.026910880\n              [,6]         [,7]         [,8]        [,9]         [,10]\n[1,] -0.0144478938 -0.025628722  0.019494461 -0.01621347  0.9991800889\n[2,]  0.0368447076  0.030070458 -0.021230890 -0.02374204 -0.0092130102\n[3,]  0.0020534930 -0.002484976 -0.001643602 -0.01257498 -0.0007675737\n[4,]  0.0009058002 -0.054845172  0.031067825 -0.13115475  0.0001556012\n[5,]  0.0043464615 -0.003596798 -0.001241720 -0.01082865  0.0001705014\n[6,] -0.8420026629  0.536730366 -0.032227601 -0.03055361  0.0017005406\n             [,11]         [,12] [,13]\n[1,] -5.946298e-05 -1.634790e-04     0\n[2,] -2.126642e-05  3.739194e-04     0\n[3,] -4.067716e-05 -1.361999e-04     0\n[4,] -1.791807e-04  9.278924e-04     0\n[5,]  5.572381e-05 -3.826366e-05     0\n[6,] -2.643574e-04 -1.367750e-04     0\n\n# The Smallest Eigenvalues\nsort(eigenvalues, decreasing = FALSE)\n\n [1] 0.000000e+00 4.470332e-05 1.350442e-04 1.988079e-02 6.474194e-02\n [6] 6.567150e-02 9.892545e-02 1.141914e-01 3.891474e-01 7.526465e-01\n[11] 8.638950e-01 1.324028e+01 1.549582e+03\n\n# The smallest eigenvalue is approximately zero\nsmallest_eigenvalue &lt;- min(eigenvalues)\nprint(smallest_eigenvalue)\n\n[1] 0\n\n# Corresponding eigenvector\nsmallest_eigenvector &lt;- eigenvectors[, which.min(eigenvalues)]\nprint(smallest_eigenvector)\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 1\n\n# Normalize the eigenvector by dividing by the largest absolute value\nnormalized_eigenvector &lt;- smallest_eigenvector / max(abs(smallest_eigenvector))\nprint(normalized_eigenvector)\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 1\n\n# Sorted normalize the eigenvector\nsort(abs(normalized_eigenvector), decreasing = T)\n\n [1] 1 0 0 0 0 0 0 0 0 0 0 0 0\n\n# Get numeric variable names (order matches eigenvector indices)\nvariable_names &lt;- colnames(delitos_data %&gt;% select(contains('24')))\n\n# Sort normalized eigenvector by absolute contribution (descending order)\nsorted_contributions &lt;- sort(abs(normalized_eigenvector), decreasing = TRUE)\n\n# Get the indices of the top contributions\ntop_indices &lt;- order(abs(normalized_eigenvector), decreasing = TRUE)\n\n# Get the names of the top variables\ntop_variable_names &lt;- variable_names[top_indices]\n\n# Print the top variable names\nprint(top_variable_names)\n\n [1] \"sum_24TR\"  \"sum_24HOM\" \"sum_24LP\"  \"sum_24VI\"  \"sum_24DS\"  \"sum_24HP\" \n [7] \"sum_24HR\"  \"sum_24HC\"  \"sum_24HA\"  \"sum_24HM\"  \"sum_24SS\"  \"sum_24SE\" \n[13] \"sum_24EX\" \n\n# Fit a regression model to confirm the relationship\nmodel &lt;- lm(sum_24TR ~ sum_24HOM + sum_24LP + sum_24VI + \n              sum_24DS + sum_24HP + sum_24HR + \n              sum_24HC + sum_24HA + sum_24HM + \n              sum_24SS + sum_24SE + sum_24EX, \n            data = data.frame(cm_delitos_data))\n\n# model &lt;- lm(sum_24SE ~ sum_24DS + sum_24EX + sum_24SS + sum_24LP + \n#               sum_24HOM + sum_24HR + sum_24VI + sum_24HM + \n#               sum_24HA + sum_24HP + sum_24HC, \n#             data = data.frame(cm_delitos_data))\n# \n# model &lt;- lm(sum_24SS ~ sum_24EX + sum_24HC + sum_24HR + \n#                   sum_24HA + sum_24DS + sum_24HM + \n#                   sum_24HOM + sum_24HP + sum_24VI + sum_24LP,\n#                 data = data.frame(cm_delitos_data))\n# \n# model &lt;- lm(sum_24HOM ~ sum_24HA + sum_24EX + sum_24HM + \n#               sum_24LP + sum_24HR + sum_24VI + \n#               sum_24HC + sum_24HP + sum_24DS, \n#             data = data.frame(cm_delitos_data))\n\nsummary(model)\n\n\nCall:\nlm(formula = sum_24TR ~ sum_24HOM + sum_24LP + sum_24VI + sum_24DS + \n    sum_24HP + sum_24HR + sum_24HC + sum_24HA + sum_24HM + sum_24SS + \n    sum_24SE + sum_24EX, data = data.frame(cm_delitos_data))\n\nResiduals:\nALL 13 residuals are 0: no residual degrees of freedom!\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)        0        NaN     NaN      NaN\nsum_24HOM          0        NaN     NaN      NaN\nsum_24LP           0        NaN     NaN      NaN\nsum_24VI           0        NaN     NaN      NaN\nsum_24DS           0        NaN     NaN      NaN\nsum_24HP           0        NaN     NaN      NaN\nsum_24HR           0        NaN     NaN      NaN\nsum_24HC           0        NaN     NaN      NaN\nsum_24HA           0        NaN     NaN      NaN\nsum_24HM           0        NaN     NaN      NaN\nsum_24SS           0        NaN     NaN      NaN\nsum_24SE           0        NaN     NaN      NaN\nsum_24EX           0        NaN     NaN      NaN\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:    NaN, Adjusted R-squared:    NaN \nF-statistic:   NaN on 12 and 0 DF,  p-value: NA\n\n# Variance Inflation Factors\nvif(model)\n\nsum_24HOM  sum_24LP  sum_24VI  sum_24DS  sum_24HP  sum_24HR  sum_24HC  sum_24HA \n      NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN \n sum_24HM  sum_24SS  sum_24SE  sum_24EX \n      NaN       NaN       NaN       NaN",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#precision-matrix",
    "href": "1-Issue-for-Decision-Making.html#precision-matrix",
    "title": "1  Issue for Decision-Making",
    "section": "1.10 Precision Matrix",
    "text": "1.10 Precision Matrix\n\n# Compute precision matrix\nS_inv &lt;- solve(cov_matrix)\n\n# Display precision matrix (should match example values)\ncat(\"Precision Matrix (S⁻¹):\\n\")\n\nPrecision Matrix (S⁻¹):\n\nprint(S_inv, digits = 4)\n\n                SEXUALES  EXTORSION  HOMICIDIO HOMICIDIO_AT SEMOVIENTES\nSEXUALES       3.215e-03 -8.726e-04 -1.113e-04   -0.0009164  -0.0012251\nEXTORSION     -8.726e-04  5.321e-03 -1.631e-03    0.0007624  -0.0034363\nHOMICIDIO     -1.113e-04 -1.631e-03  5.643e-03   -0.0017952   0.0034454\nHOMICIDIO_AT  -9.164e-04  7.624e-04 -1.795e-03    0.0321189  -0.0088897\nSEMOVIENTES   -1.225e-03 -3.436e-03  3.445e-03   -0.0088897   0.3040415\nAUTOMOTORES    2.041e-04  7.801e-05  5.364e-05    0.0009725   0.0022573\nCOMERCIO      -1.136e-04 -4.552e-04  6.273e-05   -0.0012662   0.0013710\nMOTOCICLETAS   1.840e-04 -4.914e-04  2.753e-05   -0.0017629   0.0001261\nPERSONAS      -4.556e-05 -2.713e-05  4.495e-05    0.0000565   0.0001355\nPIRATERIA      4.604e-03 -1.204e-02 -2.227e-02   -0.0173789  -0.0430171\nRESIDENCIAS    5.810e-04 -1.514e-04  5.440e-04   -0.0008682  -0.0037420\nLESIONES_AT    2.622e-04 -6.614e-05  7.982e-06   -0.0012486   0.0008816\nLESIONES      -5.447e-04  3.361e-04 -6.339e-04    0.0003602  -0.0022676\nSECUESTRO     -8.469e-03  3.365e-03 -1.698e-02   -0.0209465   0.0260576\nTERRORISMO     1.880e-03  2.579e-03 -1.664e-02    0.0058765  -0.0419760\nINTRAFAMILIAR -3.289e-04  2.034e-05  3.086e-05    0.0001188   0.0009585\n              AUTOMOTORES   COMERCIO MOTOCICLETAS   PERSONAS  PIRATERIA\nSEXUALES        2.041e-04 -1.136e-04    1.840e-04 -4.556e-05  0.0046039\nEXTORSION       7.801e-05 -4.552e-04   -4.914e-04 -2.713e-05 -0.0120439\nHOMICIDIO       5.364e-05  6.273e-05    2.753e-05  4.495e-05 -0.0222723\nHOMICIDIO_AT    9.725e-04 -1.266e-03   -1.763e-03  5.650e-05 -0.0173789\nSEMOVIENTES     2.257e-03  1.371e-03    1.261e-04  1.355e-04 -0.0430171\nAUTOMOTORES     1.905e-03  2.246e-04   -3.422e-04 -4.172e-05 -0.0056916\nCOMERCIO        2.246e-04  2.621e-03    1.129e-05 -1.678e-04 -0.0055876\nMOTOCICLETAS   -3.422e-04  1.129e-05    4.988e-04  7.604e-06  0.0057563\nPERSONAS       -4.172e-05 -1.678e-04    7.604e-06  1.718e-05  0.0004163\nPIRATERIA      -5.692e-03 -5.588e-03    5.756e-03  4.163e-04  4.2153433\nRESIDENCIAS    -2.185e-04 -1.118e-03    1.138e-04  3.177e-05  0.0049296\nLESIONES_AT     1.391e-04 -8.644e-05    2.942e-05  2.732e-06  0.0019675\nLESIONES       -1.728e-04 -1.614e-04   -1.226e-04  1.738e-05  0.0003136\nSECUESTRO      -4.267e-03  1.652e-03   -3.767e-03 -9.033e-05 -0.1859729\nTERRORISMO      3.628e-03 -1.024e-02   -6.761e-04  4.848e-04  0.2351684\nINTRAFAMILIAR  -1.970e-05  1.695e-04   -2.233e-05 -1.092e-05 -0.0020155\n              RESIDENCIAS LESIONES_AT   LESIONES  SECUESTRO TERRORISMO\nSEXUALES        5.810e-04   2.622e-04 -5.447e-04 -8.469e-03  0.0018804\nEXTORSION      -1.514e-04  -6.614e-05  3.361e-04  3.365e-03  0.0025791\nHOMICIDIO       5.440e-04   7.982e-06 -6.339e-04 -1.698e-02 -0.0166414\nHOMICIDIO_AT   -8.682e-04  -1.249e-03  3.602e-04 -2.095e-02  0.0058765\nSEMOVIENTES    -3.742e-03   8.816e-04 -2.268e-03  2.606e-02 -0.0419760\nAUTOMOTORES    -2.185e-04   1.391e-04 -1.728e-04 -4.267e-03  0.0036280\nCOMERCIO       -1.118e-03  -8.644e-05 -1.614e-04  1.652e-03 -0.0102356\nMOTOCICLETAS    1.138e-04   2.942e-05 -1.226e-04 -3.767e-03 -0.0006761\nPERSONAS        3.177e-05   2.732e-06  1.738e-05 -9.033e-05  0.0004848\nPIRATERIA       4.930e-03   1.967e-03  3.136e-04 -1.860e-01  0.2351684\nRESIDENCIAS     2.493e-03  -7.085e-05 -3.653e-04 -5.333e-04  0.0005118\nLESIONES_AT    -7.085e-05   4.446e-04 -2.556e-04  8.076e-04  0.0019385\nLESIONES       -3.653e-04  -2.556e-04  7.088e-04  2.579e-03 -0.0009210\nSECUESTRO      -5.333e-04   8.076e-04  2.579e-03  1.989e+00 -0.3486433\nTERRORISMO      5.118e-04   1.938e-03 -9.210e-04 -3.486e-01  1.4665875\nINTRAFAMILIAR  -1.318e-04   2.102e-05 -9.236e-05  1.602e-03  0.0005950\n              INTRAFAMILIAR\nSEXUALES         -3.289e-04\nEXTORSION         2.034e-05\nHOMICIDIO         3.086e-05\nHOMICIDIO_AT      1.188e-04\nSEMOVIENTES       9.585e-04\nAUTOMOTORES      -1.970e-05\nCOMERCIO          1.695e-04\nMOTOCICLETAS     -2.233e-05\nPERSONAS         -1.092e-05\nPIRATERIA        -2.016e-03\nRESIDENCIAS      -1.318e-04\nLESIONES_AT       2.102e-05\nLESIONES         -9.236e-05\nSECUESTRO         1.602e-03\nTERRORISMO        5.950e-04\nINTRAFAMILIAR     1.169e-04\n\n# Extract first row components\nfirst_row &lt;- S_inv[1,]\ndiag_element &lt;- S_inv[1,1]\n\n# Calculate regression coefficients\nbeta_coefficients &lt;- -first_row[-1]/diag_element\nprint(beta_coefficients, digits = 4)\n\n    EXTORSION     HOMICIDIO  HOMICIDIO_AT   SEMOVIENTES   AUTOMOTORES \n      0.27138       0.03462       0.28501       0.38103      -0.06347 \n     COMERCIO  MOTOCICLETAS      PERSONAS     PIRATERIA   RESIDENCIAS \n      0.03534      -0.05722       0.01417      -1.43185      -0.18070 \n  LESIONES_AT      LESIONES     SECUESTRO    TERRORISMO INTRAFAMILIAR \n     -0.08155       0.16940       2.63399      -0.58481       0.10228 \n\n# Calculate residual variance and standar error\nresidual_variance &lt;- 1/diag_element\nround(residual_variance, 2)\n\n[1] 311.01\n\nsqrt(round(residual_variance, 2))\n\n[1] 17.63548\n\n# R^2\n1 - (1/(cov_matrix[1,1] * S_inv[1,1]))\n\n[1] 0.940712\n\n# Regression coefficients\ndelitos &lt;- delitos_data %&gt;%\n  select(-BANCOS) %&gt;%\n  select(where(is.numeric))\n\nmodel &lt;- lm(SEXUALES ~ ., data = data.frame(delitos))\nsummary(model)\n\n\nCall:\nlm(formula = SEXUALES ~ ., data = data.frame(delitos))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-124.357   -2.738   -0.483    2.601  247.785 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    0.643683   0.620715   1.037 0.299944    \nEXTORSION      0.271378   0.036316   7.473 1.51e-13 ***\nHOMICIDIO      0.034617   0.038244   0.905 0.365570    \nHOMICIDIO_AT   0.285011   0.090904   3.135 0.001759 ** \nSEMOVIENTES    0.381025   0.280614   1.358 0.174774    \nAUTOMOTORES   -0.063471   0.022154  -2.865 0.004243 ** \nCOMERCIO       0.035340   0.026052   1.357 0.175190    \nMOTOCICLETAS  -0.057217   0.011254  -5.084 4.28e-07 ***\nPERSONAS       0.014169   0.002071   6.843 1.24e-11 ***\nPIRATERIA     -1.431851   1.044847  -1.370 0.170821    \nRESIDENCIAS   -0.180704   0.024888  -7.261 6.91e-13 ***\nLESIONES_AT   -0.081554   0.010477  -7.784 1.51e-14 ***\nLESIONES       0.169405   0.012646  13.396  &lt; 2e-16 ***\nSECUESTRO      2.633992   0.714179   3.688 0.000236 ***\nTERRORISMO    -0.584808   0.616549  -0.949 0.343056    \nINTRAFAMILIAR  0.102284   0.004648  22.007  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.75 on 1199 degrees of freedom\nMultiple R-squared:  0.9407,    Adjusted R-squared:   0.94 \nF-statistic:  1268 on 15 and 1199 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#linear-dependency-and-precision-matrix",
    "href": "1-Issue-for-Decision-Making.html#linear-dependency-and-precision-matrix",
    "title": "1  Issue for Decision-Making",
    "section": "1.10 Linear Dependency and Precision Matrix",
    "text": "1.10 Linear Dependency and Precision Matrix\nLinear dependency in data occurs when some variables can be expressed as linear combinations of others, leading to redundancy. This is identified through the covariance matrix \\(( \\Sigma )\\) and its eigenvalues, where a near-zero eigenvalue indicates dependency.\nThe precision matrix \\(( \\Sigma^{-1} )\\), the inverse of the covariance matrix, quantifies conditional dependencies. It highlights direct variable relationships, with zero entries indicating independence given other variables. These concepts are crucial for multicollinearity detection and improving model interpretability.\nMulticollinearity occurs when predictor variables are highly correlated, making it difficult to isolate their individual effects in a model.\n\n# Compute precision matrix\nS_inv &lt;- solve(cov_matrix)\n\n# Display precision matrix (should match example values)\ncat(\"Precision Matrix (S⁻¹):\\n\")\n\nPrecision Matrix (S⁻¹):\n\nprint(S_inv, digits = 2)\n\n          sum_24HOM sum_24LP sum_24VI sum_24DS sum_24HP sum_24HR sum_24HC\nsum_24HOM    50.236   -0.463  -0.0354    0.053   0.0115  0.05092 -0.01096\nsum_24LP     -0.463    1.301  -0.1194    0.031  -0.0250 -0.07097 -0.06546\nsum_24VI     -0.035   -0.119   0.1232   -0.297  -0.0037 -0.03237 -0.01217\nsum_24DS      0.053    0.031  -0.2971    2.774  -0.1064 -0.19038  0.09162\nsum_24HP      0.012   -0.025  -0.0037   -0.106   0.0246 -0.04986 -0.06162\nsum_24HR      0.051   -0.071  -0.0324   -0.190  -0.0499  9.15312 -0.00021\nsum_24HC     -0.011   -0.065  -0.0122    0.092  -0.0616 -0.00021  1.21690\nsum_24HA     -0.974   -0.398  -0.0249    0.370  -0.0240 -0.36650 -0.14485\nsum_24HM     -0.871   -0.311  -0.0111   -0.039  -0.0106 -0.55535 -0.12517\nsum_24EX      0.767   -0.281  -0.2388   -1.724  -0.1855 -0.11616 -0.25696\n          sum_24HA sum_24HM sum_24EX\nsum_24HOM   -0.974   -0.871     0.77\nsum_24LP    -0.398   -0.311    -0.28\nsum_24VI    -0.025   -0.011    -0.24\nsum_24DS     0.370   -0.039    -1.72\nsum_24HP    -0.024   -0.011    -0.19\nsum_24HR    -0.366   -0.555    -0.12\nsum_24HC    -0.145   -0.125    -0.26\nsum_24HA    14.783   -1.459     0.28\nsum_24HM    -1.459   10.299     0.84\nsum_24EX     0.275    0.841    15.06\n\n# Extract first row components\nfirst_row &lt;- S_inv[1,]\ndiag_element &lt;- S_inv[1,1]\n\n# Calculate regression coefficients\nbeta_coefficients &lt;- -first_row[-1]/diag_element\nprint(beta_coefficients, digits = 2)\n\nsum_24LP sum_24VI sum_24DS sum_24HP sum_24HR sum_24HC sum_24HA sum_24HM \n 0.00921  0.00070 -0.00106 -0.00023 -0.00101  0.00022  0.01939  0.01733 \nsum_24EX \n-0.01527 \n\n# Calculate residual variance and standar error\nresidual_variance &lt;- 1/diag_element\nround(residual_variance, 2)\n\n[1] 0.02\n\nsqrt(round(residual_variance, 2))\n\n[1] 0.1414214\n\n# R^2\n1 - (1/(cov_matrix[1,1] * S_inv[1,1]))\n\n[1] 0.01082961\n\n# Regression coefficients\ndelitos &lt;- delitos_data %&gt;%\n  st_drop_geometry() %&gt;%\n  select(contains('24')) %&gt;%\n  select(-sum_24TR, -sum_24SE, -sum_24SS)\n\nmodel &lt;- lm(sum_24HA ~ ., data = data.frame(delitos))\nsummary(model)\n\n\nCall:\nlm(formula = sum_24HA ~ ., data = data.frame(delitos))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0614 -0.0487 -0.0374 -0.0357  6.8000 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.0357255  0.0013145  27.178  &lt; 2e-16 ***\nsum_24HOM    0.0658787  0.0087512   7.528 5.25e-14 ***\nsum_24LP     0.0269397  0.0014036  19.194  &lt; 2e-16 ***\nsum_24VI     0.0016828  0.0004336   3.881 0.000104 ***\nsum_24DS    -0.0250139  0.0020545 -12.175  &lt; 2e-16 ***\nsum_24HP     0.0016245  0.0001938   8.384  &lt; 2e-16 ***\nsum_24HR     0.0247910  0.0037360   6.636 3.27e-11 ***\nsum_24HC     0.0097982  0.0013621   7.193 6.42e-13 ***\nsum_24HM     0.0986795  0.0039372  25.064  &lt; 2e-16 ***\nsum_24EX    -0.0186191  0.0047935  -3.884 0.000103 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2601 on 44315 degrees of freedom\nMultiple R-squared:  0.1079,    Adjusted R-squared:  0.1077 \nF-statistic: 595.4 on 9 and 44315 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "index.html#final-project-decision-making-for-organizational-management",
    "href": "index.html#final-project-decision-making-for-organizational-management",
    "title": "Advanced Data Analytics Course",
    "section": "Final Project: Decision-Making for Organizational Management",
    "text": "Final Project: Decision-Making for Organizational Management\n\nInstructions\n\nWork in groups of 3 to 4 people.\nPresent the results of applying organizational theories to a real-world scenario.\nThere will be two partial submissions and a final submission.\nEach group will present their proposed solution in a maximum of 10 minutes, applying the theories discussed in class.\nSimulate a consulting team presenting to the management and board of directors of an organization. Tailor your message to their profiles, preferences, and organizational vision to make it as personalized as possible in the video.\nGroups are free to be creative in how they convey the information.\n\n\n\nGuidelines for the Presentation\n\nOrganize Content in Layers:\n\nAlways include 2 to 3 key messages you want to convey, focusing on what decisions you want the audience to make.\nMove from general to specific details.\nStudy your audience to determine the level of detail they require.\nUse appropriate formats for each level of detail: images, infographics, presentations, executive summaries, or final reports.\n\nReorganize Key Messages:\n\nDecision-makers are always thinking: “What should I do?” or “What should I approve?”\nStart with recommendations and conclusions to address these questions upfront. This reduces impatience and keeps the audience engaged.\nExplain findings and methodology last.\n\nExample of a Strong Opening:\n\n“We are here to present the main changes in the new government’s discourse that could impact the country’s editorial agenda. We will answer the question: What are the 3 main editorial focus areas for La Silla Vacía in 2023-2024? We will start with our key conclusions and recommendations related to health, pensions, and regional security, and then explain the data analytics techniques and datasets that validate our findings.”\n\nCreate “Sticky” Messages:\n\nA “sticky” message is one that stakeholders can understand, remember, and act upon.\nAccording to the book Made to Stick, sticky messages have 6 key characteristics:\n\nSimplicity: Create a concise phrase for your key message (e.g., “Headache? Take Aspirin”).\nUnexpectedness: Generate curiosity by presenting something unexpected.\nConcreteness: Use examples to explain complex ideas.\nCredibility: Use real-life details, stories, or images to establish credibility.\nEmotionality: Connect with the audience’s values or emotions.\nStories: Use storytelling to move from macro-level results to personal, everyday experiences.\n\n\nAvoid Common Mistakes:\n\nToo much narrative or “blah blah blah” – this bores the audience.\nIgnoring report design – reference successful reports for inspiration.\nIf you must present long reports, use layered content and techniques to make them engaging.\n\n\n\n\nEvaluation Criteria\n\nPresentation and Organization (20 points):\n\nClarity and Coherence (5 points): The presentation is clear and follows a logical structure.\nCreativity in Presentation (5 points): Innovative and effective use of visual and narrative resources.\nTime Management and Group Participation (5 points): Respect the time limit and ensure equal participation from all group members.\nPersonalization and Audience Study (5 points): Tailor the message to the audience’s profile and preferences.\n\nContent and Depth (30 points):\n\nApplication of Organizational Theories (10 points): Clearly demonstrate the application of theories discussed in class.\nLayered Content and Detail (10 points): Structure content from general to specific, with an appropriate level of detail.\nUse of Key Messages and Organization (10 points): Clearly define and reorganize key messages effectively.\n\nRecommendations and Conclusions (25 points):\n\nRelevance and Coherence (10 points): Recommendations and conclusions are relevant and aligned with the analysis.\nStarting with Conclusions (5 points): Effectively begin the presentation with conclusions and recommendations.\nExplanation of Findings and Methodology (10 points): Clearly explain findings and the methodology used.\n\nPresentation of Messages (15 points):\n\nSimplicity and Concreteness (5 points): Key messages are simple and concrete.\nCredibility and Emotional Connection (5 points): Establish credibility and connect emotionally with the audience.\nUse of Stories (5 points): Effectively use storytelling to connect results with personal, everyday situations.\n\nAvoiding Common Mistakes (10 points):\n\nReducing Excessive Narrative (5 points): Avoid unnecessary or boring narrative.\nQuality of Design and Format (5 points): Ensure the report design and presentation are high-quality and effective.\n\n\n\n\nGrading Rubric\n\n\n\nCriteria\nPoints\n\n\n\n\nPresentation and Organization\n20\n\n\nContent and Depth\n30\n\n\nRecommendations and Conclusions\n25\n\n\nPresentation of Messages\n15\n\n\nAvoiding Common Mistakes\n10\n\n\nTotal\n100",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Advanced Data Analytics Course",
    "section": "0",
    "text": "0",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#class-participation",
    "href": "index.html#class-participation",
    "title": "Advanced Data Analytics Course",
    "section": "Class participation",
    "text": "Class participation",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#final-project-data-driven-decisions",
    "href": "index.html#final-project-data-driven-decisions",
    "title": "Advanced Data Analytics Course",
    "section": "Final Project: Data-Driven Decisions",
    "text": "Final Project: Data-Driven Decisions\nSimulate a consulting team presenting to the management and board of directors of an organization. Tailor your message to their profiles, preferences, and organizational vision to make it as personalized as possible.\nRecommended reading see: (Hutchinson 2017)\n\nInstructions\n\nWork in groups of 2 people.\nPresent the results of applying advance analytics to a real-world scenario.\nThere will be a final submission.\nEach group will present their proposed solution in a maximum of 10 minutes the last class.\nGroups are free to be creative in how they convey the information.\n\n\n\nGuidelines for the Presentation\n\nOrganize Content in Layers:\n\nAlways include 2 to 3 key messages you want to convey, focusing on what decisions you want the audience to make.\nMove from general to specific details.\nStudy your audience to determine the level of detail they require.\nUse appropriate formats for each level of detail: images, infographics, presentations, executive summaries, or final reports.\n\nReorganize Key Messages:\n\nDecision-makers are always thinking: “What should I do?” or “What should I approve?”\nStart with recommendations and conclusions to address these questions upfront. This reduces impatience and keeps the audience engaged.\nExplain findings and methodology last.\n\nExample of a Strong Opening:\n\n“We are here to present the main changes in the new government’s discourse that could impact the country’s editorial agenda. We will answer the question: What are the 3 main citizen security focus areas for the government in 2025? We will start with our key conclusions and recommendations related to main intervention areas and regional security strategies, and then explain the data analytics techniques and datasets that validate our findings.”\n\nCreate “Sticky” Messages:\n\nA “sticky” message is one that stakeholders can understand, remember, and act upon.\nAccording to the book Made to Stick (Heath and Heath 2007), sticky messages have 6 key characteristics:\n\nSimplicity: Create a concise phrase for your key message (e.g., “Headache? Take Aspirin”).\nUnexpectedness: Generate curiosity by presenting something unexpected.\nConcreteness: Use examples to explain complex ideas.\nCredibility: Use real-life details, stories, or images to establish credibility.\nEmotionality: Connect with the audience’s values or emotions.\nStories: Use storytelling to move from macro-level results to personal, everyday experiences.\n\n\nAvoid Common Mistakes:\n\nToo much narrative or “blah blah blah” – this bores the audience.\nIgnoring report design – reference successful reports for inspiration.\nIf you must present long reports, use layered content and techniques to make them engaging.\n\n\n\n\nEvaluation Criteria\n\nPresentation and Organization (20 points):\n\nClarity and Coherence (5 points): The presentation is clear and follows a logical structure.\nCreativity in Presentation (5 points): Innovative and effective use of visual and narrative resources.\nTime Management and Group Participation (5 points): Respect the time limit and ensure equal participation from all group members.\nPersonalization and Audience Study (5 points): Tailor the message to the audience’s profile and preferences.\n\nContent and Depth (30 points):\n\nApplication of Organizational Theories (10 points): Clearly demonstrate the application of theories discussed in class.\nLayered Content and Detail (10 points): Structure content from general to specific, with an appropriate level of detail.\nUse of Key Messages and Organization (10 points): Clearly define and reorganize key messages effectively.\n\nRecommendations and Conclusions (25 points):\n\nRelevance and Coherence (10 points): Recommendations and conclusions are relevant and aligned with the analysis.\nStarting with Conclusions (5 points): Effectively begin the presentation with conclusions and recommendations.\nExplanation of Findings and Methodology (10 points): Clearly explain findings and the methodology used.\n\nPresentation of Messages (15 points):\n\nSimplicity and Concreteness (5 points): Key messages are simple and concrete.\nCredibility and Emotional Connection (5 points): Establish credibility and connect emotionally with the audience.\nUse of Stories (5 points): Effectively use storytelling to connect results with personal, everyday situations.\n\nAvoiding Common Mistakes (10 points):\n\nReducing Excessive Narrative (5 points): Avoid unnecessary or boring narrative.\nQuality of Design and Format (5 points): Ensure the report design and presentation are high-quality and effective.\n\n\n\n\nGrading Rubric\n\n\n\nCriteria\nPoints\n\n\n\n\nPresentation and Organization\n20\n\n\nContent and Depth\n30\n\n\nRecommendations and Conclusions\n25\n\n\nPresentation of Messages\n15\n\n\nAvoiding Common Mistakes\n10\n\n\nTotal\n100",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#class-participation-assessment-40-of-the-total-course-score",
    "href": "index.html#class-participation-assessment-40-of-the-total-course-score",
    "title": "Advanced Data Analytics Course",
    "section": "Class Participation Assessment (40% of the total course score)",
    "text": "Class Participation Assessment (40% of the total course score)\nClass participation will be assessed based on the depth and quality of analysis conducted on the course content and data results presented throughout the sessions. Students are expected to actively engage with the materials, providing meaningful insights and interpretations in the GitHub repository.\nAs part of their evaluation, they must submit a well-structured generative AI prompt that demonstrates their understanding and ability to apply the concepts learned. This prompt should effectively guide AI models to generate relevant analyses or insights related to the course topics. The participation component, including the submission of the AI prompt and your own analysis, will contribute 40% to the total course score.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#final-project-data-driven-decisions-60-of-the-total-course-score",
    "href": "index.html#final-project-data-driven-decisions-60-of-the-total-course-score",
    "title": "Advanced Data Analytics Course",
    "section": "Final Project: Data-Driven Decisions (60% of the total course score)",
    "text": "Final Project: Data-Driven Decisions (60% of the total course score)\nSimulate a consulting team presenting to the management and board of directors of an organization. Tailor your message to their profiles, preferences, and organizational vision to make it as personalized as possible.\nRecommended reading see: (Hutchinson 2017)\n\nInstructions\n\nWork in groups of 2 people.\nPresent the results of applying advance analytics to a real-world scenario.\nThere will be a final submission.\nEach group will present their proposed solution in a maximum of 10 minutes the last class.\nGroups are free to be creative in how they convey the information.\nWhen submitting activities, include the prompts you used to generate any AI-assisted content.\n\n\n\nGuidelines for the Presentation\n\nOrganize Content in Layers:\n\nAlways include 2 to 3 key messages you want to convey, focusing on what decisions you want the audience to make.\nMove from general to specific details.\nStudy your audience to determine the level of detail they require.\nUse appropriate formats for each level of detail: images, infographics, presentations, executive summaries, or final reports.\n\nReorganize Key Messages:\n\nDecision-makers are always thinking: “What should I do?” or “What should I approve?”\nStart with recommendations and conclusions to address these questions upfront. This reduces impatience and keeps the audience engaged.\nExplain findings and methodology last.\n\nExample of a Strong Opening:\n\n“We are here to present the main changes in the new government’s discourse that could impact the country’s editorial agenda. We will answer the question: What are the 3 main citizen security focus areas for the government in 2025? We will start with our key conclusions and recommendations related to main intervention areas and regional security strategies, and then explain the data analytics techniques and datasets that validate our findings.”\n\nCreate “Sticky” Messages:\n\nA “sticky” message is one that stakeholders can understand, remember, and act upon.\nAccording to the book Made to Stick (Heath and Heath 2007), sticky messages have 6 key characteristics:\n\nSimplicity: Create a concise phrase for your key message (e.g., “Headache? Take Aspirin”).\nUnexpectedness: Generate curiosity by presenting something unexpected.\nConcreteness: Use examples to explain complex ideas.\nCredibility: Use real-life details, stories, or images to establish credibility.\nEmotionality: Connect with the audience’s values or emotions.\nStories: Use storytelling to move from macro-level results to personal, everyday experiences.\n\n\nAvoid Common Mistakes:\n\nToo much narrative or “blah blah blah” – this bores the audience.\nIgnoring report design – reference successful reports for inspiration.\nIf you must present long reports, use layered content and techniques to make them engaging.\n\n\n\n\nEvaluation Criteria\n\nPresentation and Organization (20 points):\n\nClarity and Coherence (5 points): The presentation is clear and follows a logical structure.\nCreativity in Presentation (5 points): Innovative and effective use of visual and narrative resources.\nTime Management and Group Participation (5 points): Respect the time limit and ensure equal participation from all group members.\nPersonalization and Audience Study (5 points): Tailor the message to the audience’s profile and preferences.\n\nContent and Depth (30 points):\n\nApplication of Advance Analytics Concepts (10 points): Clearly demonstrate the application of theories discussed in class.\nLayered Content and Detail (10 points): Structure content from general to specific, with an appropriate level of detail.\nUse of Key Messages and Organization (10 points): Clearly define and reorganize key messages effectively.\n\nRecommendations and Conclusions (25 points):\n\nRelevance and Coherence (10 points): Recommendations and conclusions are relevant and aligned with the analysis.\nStarting with Conclusions (5 points): Effectively begin the presentation with conclusions and recommendations.\nExplanation of Findings and Methodology (10 points): Clearly explain findings and the methodology used.\n\nPresentation of Messages (15 points):\n\nSimplicity and Concreteness (5 points): Key messages are simple and concrete.\nCredibility and Emotional Connection (5 points): Establish credibility and connect emotionally with the audience.\nUse of Stories (5 points): Effectively use storytelling to connect results with personal, everyday situations.\n\nAvoiding Common Mistakes (10 points):\n\nReducing Excessive Narrative (5 points): Avoid unnecessary or boring narrative.\nQuality of Design and Format (5 points): Ensure the report design and presentation are high-quality and effective.\n\n\n\n\n\nCriteria\nPoints\n\n\n\n\nPresentation and Organization\n20\n\n\nContent and Depth\n30\n\n\nRecommendations and Conclusions\n25\n\n\nPresentation of Messages\n15\n\n\nAvoiding Common Mistakes\n10\n\n\nTotal\n100",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#recommended-readings-see",
    "href": "index.html#recommended-readings-see",
    "title": "Advanced Data Analytics Course",
    "section": "Recommended readings see:",
    "text": "Recommended readings see:\n\nCollective intelligence: short-term anticipation of coexistence issues (Perez-Coronado 2016a)\nHuman Development Oriented Policing (Perez-Coronado 2016b)\nAnticipative decision-making committees for human security\nData analytics for citizen security (Servicio de Policía 2024)\nLa Silla Vacía\n\n\n\n\n\nHeath, Chip, and Dan Heath. 2007. Made to Stick: Why Some Ideas Survive and Others Die. New York: Random House.\n\n\nHutchinson, Kylie. 2017. A Short Primer on Innovative Evaluation Reporting. First. Kylie Hutchinson.\n\n\nPerez-Coronado, Andres. 2016a. “Inteligencia Colectiva: Anticipación a Corto Plazo de Las Problemáticas de Convivencia.” Revista Criminalidad 58: 223–40. https://doi.org/https://doi.org/10.47741/17943108.120.\n\n\n———. 2016b. Policía Para El Desarrollo Humano (PDH). Primera. Editorial Ibanez.\n\n\nServicio de Policía, Jefatura Nacional del. 2024. Analítica de Datos Para La Seguridad Ciudadana. Edited by Jenny Andrea Lozano Medina. Editorial de la Dirección de Educación Policial de la Policía Nacional de Colombia. https://doi.org/10.22335/2qjz0m48.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#real-problem-to-tackle-ciminal-conexion-are-speading.",
    "href": "1-Issue-for-Decision-Making.html#real-problem-to-tackle-ciminal-conexion-are-speading.",
    "title": "1  Issue for Decision-Making",
    "section": "1.13 Real problem to tackle: ciminal conexion are speading.",
    "text": "1.13 Real problem to tackle: ciminal conexion are speading.\n\n1.13.1 Mathematical Definitions:\n\nPolygons: Represented as \\(P = \\{ p_1, p_2, \\dots, p_n \\}\\) where each polygon \\(( p_i )\\) has geometric and attribute data.\nPhenomenon: A discrete or continuous variable \\(( Y )\\) observed across \\(( P )\\).\nAdjacency Matrix: \\(( A )\\) where\n\\(A_{ij} = \\begin{cases} 1, & \\text{if } p_i \\text{ and } p_j \\text{ share a boundary} \\\\ 0, & \\text{otherwise} \\end{cases}\\)\nDistance Matrix: \\(( D )\\) where \\(( D_{ij} )\\) represents the distance between the centroids of \\(( p_i )\\) and \\(( p_j )\\).\n\n\n\n1.13.2 Phenomenon Classification:\nLocal (Within Polygon)\n\nDefinition: Phenomenon occurs exclusively inside a single polygon \\(( p_i )\\).\nMath Model:\n[ Y_i = f( p_i) ]\nAnalytics:\n\nPoint-in-Polygon Analysis: Validate containment.\nSpatial Autocorrelation: Check if ( Y_i ) is independent of neighbors (Moran’s ( I ), Geary’s ( C )).\nRegression: Model ( Y_i ) using internal predictors (e.g., population density).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#local-within-polygon",
    "href": "1-Issue-for-Decision-Making.html#local-within-polygon",
    "title": "1  Issue for Decision-Making",
    "section": "2.1 2.1 Local (Within Polygon)",
    "text": "2.1 2.1 Local (Within Polygon)\n\nDefinition: Phenomenon occurs exclusively inside a single polygon ( p_i ).\nMath Model:\n[ Y_i = f( p_i) ]\nAnalytics:\n\nPoint-in-Polygon Analysis: Validate containment.\nSpatial Autocorrelation: Check if ( Y_i ) is independent of neighbors (Moran’s ( I ), Geary’s ( C )).\nRegression: Model ( Y_i ) using internal predictors (e.g., population density).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#subnational-cluster-of-neighbors",
    "href": "1-Issue-for-Decision-Making.html#subnational-cluster-of-neighbors",
    "title": "1  Issue for Decision-Making",
    "section": "1.14 2.2 Subnational (Cluster of Neighbors)",
    "text": "1.14 2.2 Subnational (Cluster of Neighbors)\n\nDefinition: Phenomenon clusters among adjacent polygons.\nMath Model: [ Y_i = _0 + 1 {j N(i)} Y_j + ] where ( N(i) ) are the neighbors of ( p_i ).\nAnalytics:\n\nSpatial Clustering: Techniques like DBSCAN or Moran’s ( I ).\nSpatial Lag Models (SAR): Incorporate neighbor effects.\nHotspot Analysis: Using Getis-Ord ( G_i^* ).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#nationalinternational-neighbors-non-neighbors",
    "href": "1-Issue-for-Decision-Making.html#nationalinternational-neighbors-non-neighbors",
    "title": "1  Issue for Decision-Making",
    "section": "1.15 2.3 National/International (Neighbors + Non-Neighbors)",
    "text": "1.15 2.3 National/International (Neighbors + Non-Neighbors)\n\nDefinition: Phenomenon spans both adjacent and non-adjacent polygons (e.g., trade networks).\nMath Model: [ Y_i = f(j w{ij} Y_j) ] where ( w_{ij} ) depends on distance or network connectivity.\nAnalytics:\n\nNetwork Analysis: Using centrality metrics (degree, betweenness).\nGravity Models: [ w_{ij} = ]\nSpatial Regression with Distance Weights: Models such as CAR and MAUP-adjusted approaches.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#local-subnational-clear-administrative-boundaries",
    "href": "1-Issue-for-Decision-Making.html#local-subnational-clear-administrative-boundaries",
    "title": "1  Issue for Decision-Making",
    "section": "1.14 2.4 Local-Subnational (Clear Administrative Boundaries)",
    "text": "1.14 2.4 Local-Subnational (Clear Administrative Boundaries)\n\nDefinition: Clear separation between local (city) and subnational (state) boundaries among neighbors.\nMath Model: [ Y_i = + _i + ]\nAnalytics:\n\nMultilevel Modeling: Using mixed-effects models.\nGIS Overlay Analysis: To intersect city and state boundaries.\nSpatial ANOVA: To test for differences across administrative levels.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#local-nationalinternational-non-neighbors",
    "href": "1-Issue-for-Decision-Making.html#local-nationalinternational-non-neighbors",
    "title": "1  Issue for Decision-Making",
    "section": "1.14 2.5 Local-National/International (Non-Neighbors)",
    "text": "1.14 2.5 Local-National/International (Non-Neighbors)\n\nDefinition: Phenomenon connects non-neighboring polygons with clear boundaries (e.g., migration between distant cities).\nMath Model: [ Y_i = f(Y_j) ] where ( A_{ij} = 0 ) (i.e., not adjacent) but ( D_{ij} ) is significant.\nAnalytics:\n\nSpatial Regression with Distance Decay: Such as exponential decay models.\nNetwork Autocorrelation Models: Utilizing inverse distance weights.\nCommunity Detection: For instance, using the Louvain algorithm to identify non-spatial clusters.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#local-subnational-fuzzy-boundaries",
    "href": "1-Issue-for-Decision-Making.html#local-subnational-fuzzy-boundaries",
    "title": "1  Issue for Decision-Making",
    "section": "1.15 2.6 Local-Subnational (Fuzzy Boundaries)",
    "text": "1.15 2.6 Local-Subnational (Fuzzy Boundaries)\n\nDefinition: Ambiguous administrative boundaries (e.g., overlapping jurisdictions).\nMath Model:\n\nFuzzy Membership:\n[ _{ik} ] indicating the degree to which ( p_i ) belongs to region ( k ).\n\nAnalytics:\n\nFuzzy Clustering: Such as fuzzy ( c )-means.\nSpatially Weighted Regression: [ Y_i = j {ij} Y_j ]\nBayesian Hierarchical Models: To account for boundary uncertainty.\n\nDivide stations by regions of analysis to explain the spatial correlations.\nReplicate exploratory analysis in the selected regions.\nLoad your work by GitHub pull request.\nDefine the issue for decision-making.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#confronting-a-critical-challenge-the-proliferation-of-spatial-criminal-networks",
    "href": "1-Issue-for-Decision-Making.html#confronting-a-critical-challenge-the-proliferation-of-spatial-criminal-networks",
    "title": "1  Issue for Decision-Making",
    "section": "1.13 Confronting a Critical Challenge: The Proliferation of Spatial Criminal Networks",
    "text": "1.13 Confronting a Critical Challenge: The Proliferation of Spatial Criminal Networks\n\n1.13.1 Mathematical Definitions:\n\nPolygons: Represented as \\(P = \\{ p_1, p_2, \\dots, p_n \\}\\) where each polygon \\(( p_i )\\) has geometric and attribute data.\nPhenomenon: A discrete or continuous variable \\(( Y )\\) observed across \\(( P )\\).\nAdjacency Matrix: \\(( A )\\) where\n\\(A_{ij} = \\begin{cases} 1, & \\text{if } p_i \\text{ and } p_j \\text{ share a boundary} \\\\ 0, & \\text{otherwise} \\end{cases}\\)\nDistance Matrix: \\(( D )\\) where \\(( D_{ij} )\\) represents the distance between the centroids of \\(( p_i )\\) and \\(( p_j )\\).\n\n\n\n1.13.2 Phenomenon Classification:\n\nLocal (Within Polygon): Phenomenon occurs exclusively inside a single polygon \\(( p_i )\\). Thus, \\(Y_i = f(\\text{Internal factors of } p_i)\\).\nSubnational (Cluster of Neighbors): Phenomenon clusters among adjacent polygons. Thus, \\(Y_i = \\beta_0 + \\beta_1 \\sum_{j \\in N(i)} Y_j + \\epsilon\\) where \\(( N(i) )\\) are the neighbors of \\(( p_i )\\).\nNational/International (Neighbors + Non-Neighbors): Phenomenon spans both adjacent and non-adjacent polygons (e.g., trade networks). Thus, \\(Y_i = f\\left(\\sum_j w_{ij} Y_j\\right)\\) where \\(( w_{ij} )\\) depends on distance or network connectivity.\nLocal-Subnational (Clear Boundaries): Clear separation between local (city) and subnational (state) boundaries among neighbors. Thus, \\(Y_i = \\alpha + \\gamma \\cdot \\text{State}_i + \\epsilon\\).\nLocal-National/International (Non-Neighbors): Phenomenon connects non-neighboring polygons with clear boundaries (e.g., migration between distant cities). Thus, \\(Y_i = f(Y_j)\\) where \\(( A_{ij} = 0 )\\) (i.e., not adjacent) but \\(( D_{ij} )\\) is significant.\nLocal-Subnational (Fuzzy Boundaries): Ambiguous administrative boundaries (e.g., overlapping jurisdictions). Thus, \\(\\mu_{ik} \\in [0,1]\\) indicating the degree to which \\(( p_i )\\) belongs to region \\(( k )\\).\nAnalytics:\n\nFuzzy Clustering: Such as fuzzy ( c )-means.\nSpatially Weighted Regression: [ Y_i = j {ij} Y_j ]\nBayesian Hierarchical Models: To account for boundary uncertainty.\n\nDivide stations by regions of analysis to explain the spatial correlations.\nReplicate exploratory analysis in the selected regions.\nLoad your work by GitHub pull request.\nDefine the issue for decision-making.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#confronting-a-critical-challenge-the-proliferation-of-spatial-criminal-phenomenon",
    "href": "1-Issue-for-Decision-Making.html#confronting-a-critical-challenge-the-proliferation-of-spatial-criminal-phenomenon",
    "title": "1  Issue for Decision-Making",
    "section": "1.13 Confronting a Critical Challenge: The Proliferation of Spatial Criminal Phenomenon",
    "text": "1.13 Confronting a Critical Challenge: The Proliferation of Spatial Criminal Phenomenon\n\n1.13.1 Mathematical Definitions:\n\nPolygons: Represented as \\(P = \\{ p_1, p_2, \\dots, p_n \\}\\) where each polygon \\(( p_i )\\) has geometric and attribute data.\nPhenomenon: A discrete or continuous variable \\(( Y )\\) observed across \\(( P )\\).\nAdjacency Matrix: \\(( A )\\) where\n\\(A_{ij} = \\begin{cases} 1, & \\text{if } p_i \\text{ and } p_j \\text{ share a boundary} \\\\ 0, & \\text{otherwise} \\end{cases}\\)\nDistance Matrix: \\(( D )\\) where \\(( D_{ij} )\\) represents the distance between the centroids of \\(( p_i )\\) and \\(( p_j )\\).\n\n\n\n1.13.2 Phenomenon Classification:\n\nLocal (Within Polygon): Phenomenon occurs exclusively inside a single polygon \\(( p_i )\\). Thus, \\(Y_i = f(\\text{Internal factors of } p_i)\\).\nSubnational (Cluster of Neighbors): Phenomenon clusters among adjacent polygons. Thus, \\(Y_i = \\beta_0 + \\beta_1 \\sum_{j \\in N(i)} Y_j + \\epsilon\\) where \\(( N(i) )\\) are the neighbors of \\(( p_i )\\).\nNational/International (Neighbors + Non-Neighbors): Phenomenon spans both adjacent and non-adjacent polygons (e.g., trade networks). Thus, \\(Y_i = f\\left(\\sum_j w_{ij} Y_j\\right)\\) where \\(( w_{ij} )\\) depends on distance or network connectivity.\nLocal-Subnational (Clear Boundaries): Clear separation between local (city) and subnational (state) boundaries among neighbors. Thus, \\(Y_i = \\alpha + \\gamma \\cdot \\text{State}_i + \\epsilon\\).\nLocal-National/International (Non-Neighbors): Phenomenon connects non-neighboring polygons with clear boundaries (e.g., migration between distant cities). Thus, \\(Y_i = f(Y_j)\\) where \\(( A_{ij} = 0 )\\) (i.e., not adjacent) but \\(( D_{ij} )\\) is significant.\nLocal-Subnational (Fuzzy Boundaries): Ambiguous administrative boundaries (e.g., overlapping jurisdictions). Thus, \\(\\mu_{ik} \\in [0,1]\\) indicating the degree to which \\(( p_i )\\) belongs to region \\(( k )\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#project-activities",
    "href": "1-Issue-for-Decision-Making.html#project-activities",
    "title": "1  Issue for Decision-Making",
    "section": "1.14 Project Activities",
    "text": "1.14 Project Activities\n\nSelect stations that align with your analysis interests to illustrate spatial criminal phenomena.\nReplicate the exploratory analysis performed on the selected stations as demonstrated in the lecture.\nDefine the issue for decision-making that you propose.\nUpload your work by creating a GitHub pull request with your group’s .qmd file.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#tackling-a-critical-challenge-the-proliferation-of-spatial-criminal-phenomena",
    "href": "1-Issue-for-Decision-Making.html#tackling-a-critical-challenge-the-proliferation-of-spatial-criminal-phenomena",
    "title": "1  Issue for Decision-Making",
    "section": "1.11 Tackling a Critical Challenge: The Proliferation of Spatial Criminal Phenomena",
    "text": "1.11 Tackling a Critical Challenge: The Proliferation of Spatial Criminal Phenomena\n\n1.11.1 Mathematical Definitions:\n\nPolygons: Represented as \\(P = \\{ p_1, p_2, \\dots, p_n \\}\\) where each polygon \\(( p_i )\\) has geometric and attribute data.\nPhenomenon: A discrete or continuous variable \\(( Y )\\) observed across \\(( P )\\).\nAdjacency Matrix: \\(( A )\\) where\n\\(A_{ij} = \\begin{cases} 1, & \\text{if } p_i \\text{ and } p_j \\text{ share a boundary} \\\\ 0, & \\text{otherwise} \\end{cases}\\)\nDistance Matrix: \\(( D )\\) where \\(( D_{ij} )\\) represents the distance between the centroids of \\(( p_i )\\) and \\(( p_j )\\).\n\n\n\n1.11.2 Phenomenon Classification:\n\nLocal (Within Polygon): Phenomenon occurs exclusively inside a single polygon \\(( p_i )\\). Thus, \\(Y_i = f(\\text{Internal factors of } p_i)\\).\nSubnational (Cluster of Neighbors): Phenomenon clusters among adjacent polygons. Thus, \\(Y_i = \\beta_0 + \\beta_1 \\sum_{j \\in N(i)} Y_j + \\epsilon\\) where \\(( N(i) )\\) are the neighbors of \\(( p_i )\\).\nNational/International (Neighbors + Non-Neighbors): Phenomenon spans both adjacent and non-adjacent polygons (e.g., trade networks). Thus, \\(Y_i = f\\left(\\sum_j w_{ij} Y_j\\right)\\) where \\(( w_{ij} )\\) depends on distance or network connectivity.\nLocal-Subnational (Clear Boundaries): Clear separation between local (city) and subnational (state) boundaries among neighbors. Thus, \\(Y_i = \\alpha + \\gamma \\cdot \\text{State}_i + \\epsilon\\).\nLocal-National/International (Non-Neighbors): Phenomenon connects non-neighboring polygons with clear boundaries (e.g., migration between distant cities). Thus, \\(Y_i = f(Y_j)\\) where \\(( A_{ij} = 0 )\\) (i.e., not adjacent) but \\(( D_{ij} )\\) is significant.\nLocal-Subnational (Fuzzy Boundaries): Ambiguous administrative boundaries (e.g., overlapping jurisdictions). Thus, \\(\\mu_{ik} \\in [0,1]\\) indicating the degree to which \\(( p_i )\\) belongs to region \\(( k )\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#final-project-activities",
    "href": "1-Issue-for-Decision-Making.html#final-project-activities",
    "title": "1  Issue for Decision-Making",
    "section": "1.12 Final Project Activities",
    "text": "1.12 Final Project Activities\n\nGroup stations based on your analysis interests to illustrate spatial criminal phenomena.\nDefine the issue for decision-making that you propose supported by the exploratory analysis of multidimensional data.\nUpload your work by creating a GitHub pull request with your group’s .qmd file in the appendix section.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "1-Issue-for-Decision-Making.html#class-participation-assessment",
    "href": "1-Issue-for-Decision-Making.html#class-participation-assessment",
    "title": "1  Issue for Decision-Making",
    "section": "1.13 Class Participation Assessment",
    "text": "1.13 Class Participation Assessment\n\nReplicate the exploratory analysis on the selected stations as demonstrated in the lecture, and compare your results with those of other groups.\n\nUpload your analysis under the respective subsections titled Augmented Data Analyst and Prompts.\n\n\n\n\n\nPeña, D. 2002. Análisis Multivariante de Datos. McGraw-Hill Interamericana de España S.L. https://books.google.com.co/books?id=TrVlAAAACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Issue for Decision-Making</span>"
    ]
  },
  {
    "objectID": "3-Imputing-and-Linking-Data.html",
    "href": "3-Imputing-and-Linking-Data.html",
    "title": "3  Imputing and Linking Data",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Imputing and Linking Data</span>"
    ]
  },
  {
    "objectID": "Appendix-1.html",
    "href": "Appendix-1.html",
    "title": "Appendix 1",
    "section": "",
    "text": "Augmented Data Analyst",
    "crumbs": [
      "Appendix 1"
    ]
  },
  {
    "objectID": "Appendix-1.html#prompts",
    "href": "Appendix-1.html#prompts",
    "title": "Appendix 1",
    "section": "Prompts",
    "text": "Prompts",
    "crumbs": [
      "Appendix 1"
    ]
  }
]